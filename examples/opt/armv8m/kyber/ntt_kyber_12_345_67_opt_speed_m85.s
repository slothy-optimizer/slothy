
///
/// Copyright (c) 2021 Arm Limited
/// Copyright (c) 2022 Hanno Becker
/// Copyright (c) 2023 Amin Abdulrahman, Matthias Kannwischer
/// SPDX-License-Identifier: MIT
///
/// Permission is hereby granted, free of charge, to any person obtaining a copy
/// of this software and associated documentation files (the "Software"), to deal
/// in the Software without restriction, including without limitation the rights
/// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
/// copies of the Software, and to permit persons to whom the Software is
/// furnished to do so, subject to the following conditions:
///
/// The above copyright notice and this permission notice shall be included in all
/// copies or substantial portions of the Software.
///
/// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
/// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
/// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
/// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
/// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
/// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
/// SOFTWARE.
///

.data
.p2align 4
roots:
#include "ntt_kyber_12_345_67_twiddles.s"
.text

#define QSTACK4   (0*16)
#define QSTACK5   (1*16)
#define QSTACK6   (2*16)
#define STACK0 (3*16)

#define POS_ROOT_1   1
#define POS_ROOT_2   2
#define POS_ROOT_3   3
#define POS_ROOT_4   4
#define POS_ROOT_5   5
#define POS_ROOT_6   6

#define STACK_SIZE (3*16 + 8)

.macro qsave loc, a       // @slothy:no-unfold
        vstrw.32 \a, [sp, #\loc\()]
.endm
.macro qrestore a, loc    // @slothy:no-unfold
        vldrw.32 \a, [sp, #\loc\()]
.endm
.macro restored a, b, loc // @slothy:no-unfold
        ldrd \a, \b, [sp, #\loc\()]
.endm
.macro saved loc, a, b    // @slothy:no-unfold
        strd \a, \b, [sp, #\loc\()]
.endm
.macro restore a, loc     // @slothy:no-unfold
        ldr \a, [sp, #\loc\()]
.endm
.macro save loc, a        // @slothy:no-unfold
        str \a, [sp, #\loc\()]
.endm

// Barrett multiplication
.macro mulmod dst, src, const, const_tw
        vmul.s16       \dst,  \src, \const
        vqrdmulh.s16   \src,  \src, \const_tw
        vmla.s16       \dst,  \src, modulus
.endm

.macro ct_butterfly a, b, root, root_tw
        mulmod tmp, \b, \root, \root_tw
        vsub.u16       \b,    \a, tmp
        vadd.u16       \a,    \a, tmp
.endm

// Aligns stack =0 mod 16
.macro align_stack_do // @slothy:no-unfold
        mov r11, sp
        and r12, r11, #0xC
        sub sp, sp, r12      // Align stack to 16 byte
        sub sp, sp, #16
        str r12, [sp]
.endm

// Reverts initial stack correction
.macro align_stack_undo // @slothy:no-unfold
        ldr r12, [sp]
        add sp, sp, #16
        add sp, sp, r12
.endm

.align 4
roots_addr: .word roots
.syntax unified
.type ntt_kyber_12_345_67_opt_speed_m85, %function
.global ntt_kyber_12_345_67_opt_speed_m85

        modulus  .req r12
        r_ptr .req r11
        .equ modulus_const, -3329

        in           .req r0
        inp          .req r1
        in_low       .req r0
        in_high      .req r1

        root0    .req r2
        root0_tw .req r3
        root1    .req r4
        root1_tw .req r5
        root2    .req r6
        root2_tw .req r7

        data0 .req q0
        data1 .req q1
        data2 .req q2
        data3 .req q3
        data4 .req q1
        data5 .req q2
        data6 .req q3
        data7 .req q4

        tmp     .req q7

        rtmp    .req r3
        rtmp_tw .req r4

        qtmp    .req q5
        qtmp_tw .req q6

ntt_kyber_12_345_67_opt_speed_m85:

        push {r4-r11,lr}
        // Save MVE vector registers
        vpush {d8-d15}
        align_stack_do

        sub sp, sp, #STACK_SIZE
        movw modulus, #:lower16:modulus_const
        ldr  r_ptr, roots_addr

        // Layers 1,2

        save STACK0, in
        add in_high, in_low, #(2*128)
        ldrd root0, root0_tw, [r_ptr], #+24
        ldrd root1, root1_tw, [r_ptr, #-16]
        ldrd root2, root2_tw, [r_ptr, #-8]

        mov lr, #8
        .p2align 2
                                          // Instructions:    2
                                          // Expected cycles: 2
                                          // Expected IPC:    1.00
                                          //
                                          // Wall time:     0.00s
                                          // User time:     0.00s
                                          //
                                          // ----- cycle (expected) ------>
                                          // 0                        25
                                          // |------------------------|----
        vldrw.32 q4, [r1, #(2*64)]        // *.............................
        vmul.S16 q5, q4, r2               // .*............................

                                           // ------ cycle (expected) ------>
                                           // 0                        25
                                           // |------------------------|-----
        // vldrw.32 q4, [r1, #(2*64)]      // *..............................
        // vmul.S16 q5, q4, r2             // .*.............................

        sub lr, lr, #1
.p2align 2
layer12_loop:
                                                // Instructions:    28
                                                // Expected cycles: 28
                                                // Expected IPC:    1.00
                                                //
                                                // Wall time:     2.88s
                                                // User time:     2.88s
                                                //
                                                // ----- cycle (expected) ------>
                                                // 0                        25
                                                // |------------------------|----
        vqrdmulh.S16 q4, q4, r3                 // *.............................
        vldrw.32 q2, [r1]                       // .*............................
        vmla.S16 q5, q4, r12                    // ..*...........................
        vldrw.32 q6, [r0]                       // ...*..........................
        vmul.S16 q7, q2, r2                     // ....*.........................
        vldrw.32 q4, [r1, #(2*64)]              // .....e........................
        vqrdmulh.S16 q3, q2, r3                 // ......*.......................
        vldrw.32 q1, [r0, #(2*64)]              // .......*......................
        vmla.S16 q7, q3, r12                    // ........*.....................
        vadd.U16 q0, q1, q5                     // .........*....................
        vqrdmulh.S16 q2, q0, r5                 // ..........*...................
        vadd.U16 q3, q6, q7                     // ...........*..................
        vmul.S16 q0, q0, r4                     // ............*.................
        vsub.U16 q1, q1, q5                     // .............*................
        vmla.S16 q0, q2, r12                    // ..............*...............
        vsub.U16 q6, q6, q7                     // ...............*..............
        vmul.S16 q5, q1, r6                     // ................*.............
        vsub.U16 q7, q3, q0                     // .................*............
        vqrdmulh.S16 q1, q1, r7                 // ..................*...........
        vadd.U16 q3, q3, q0                     // ...................*..........
        vmla.S16 q5, q1, r12                    // ....................*.........
        vstrw.U32 q7, [r0, #(2*64 - 16)]        // .....................*........
        vsub.U16 q1, q6, q5                     // ......................*.......
        vstrw.U32 q3, [r0], #16                 // .......................*......
        vadd.U16 q6, q6, q5                     // ........................*.....
        vstrw.U32 q1, [r1, #(2*64 - 16)]        // .........................*....
        vmul.S16 q5, q4, r2                     // ..........................e...
        vstrw.U32 q6, [r1], #16                 // ...........................*..

                                                 // ---------------- cycle (expected) ---------------->
                                                 // 0                        25
                                                 // |------------------------|-------------------------
        // vldrw.32 q0, [r0]                     // .......................'..*........................
        // vldrw.32 q1, [r0, #(2*64)]            // ..~....................'......*....................
        // vldrw.32 q2, [r1]                     // .......................'*..........................
        // vldrw.32 q3, [r1, #(2*64)]            // e......................'....~......................
        // vmul.s16       q7,  q2, r2            // .......................'...*.......................
        // vqrdmulh.s16   q2,  q2, r3            // .~.....................'.....*.....................
        // vmla.s16       q7,  q2, r12           // ...~...................'.......*...................
        // vsub.u16       q2,    q0, q7          // ..........~............'..............*............
        // vadd.u16       q0,    q0, q7          // ......~................'..........*................
        // vmul.s16       q7,  q3, r2            // .....................e.'.........................~.
        // vqrdmulh.s16   q3,  q3, r3            // .......................*...........................
        // vmla.s16       q7,  q3, r12           // .......................'.*.........................
        // vsub.u16       q3,    q1, q7          // ........~..............'............*..............
        // vadd.u16       q1,    q1, q7          // ....~..................'........*..................
        // vmul.s16       q7,  q1, r4            // .......~...............'...........*...............
        // vqrdmulh.s16   q1,  q1, r5            // .....~.................'.........*.................
        // vmla.s16       q7,  q1, r12           // .........~.............'.............*.............
        // vsub.u16       q1,    q0, q7          // ............~..........'................*..........
        // vadd.u16       q0,    q0, q7          // ..............~........'..................*........
        // vmul.s16       q7,  q3, r6            // ...........~...........'...............*...........
        // vqrdmulh.s16   q3,  q3, r7            // .............~.........'.................*.........
        // vmla.s16       q7,  q3, r12           // ...............~.......'...................*.......
        // vsub.u16       q3,    q2, q7          // .................~.....'.....................*.....
        // vadd.u16       q2,    q2, q7          // ...................~...'.......................*...
        // vstrw.u32 q0, [r0], #16               // ..................~....'......................*....
        // vstrw.u32 q1, [r0, #(2*64 - 16)]      // ................~......'....................*......
        // vstrw.u32 q2, [r1], #16               // ......................~'..........................*
        // vstrw.u32 q3, [r1, #(2*64 - 16)]      // ....................~..'........................*..

        le lr, layer12_loop
        layer12_loop_end:
                                                           // Instructions:    73
                                                           // Expected cycles: 73
                                                           // Expected IPC:    1.00
                                                           //
                                                           // Wall time:     5.99s
                                                           // User time:     5.99s
                                                           //
                                                           // --------------------------- cycle (expected) --------------------------->
                                                           // 0                        25                       50
                                                           // |------------------------|------------------------|----------------------
        vqrdmulh.S16 q0, q4, r3                            // *........................................................................
        vldrw.32 q2, [r0, #(2*64)]                         // .*.......................................................................
        vmla.S16 q5, q0, r12                               // ..*......................................................................
        vldrw.32 q7, [r1]                                  // ...*.....................................................................
        vqrdmulh.S16 q3, q7, r3                            // ....*....................................................................
        vsub.U16 q4, q2, q5                                // .....*...................................................................
        vmul.S16 q1, q7, r2                                // ......*..................................................................
        vadd.U16 q2, q2, q5                                // .......*.................................................................
        vmla.S16 q1, q3, r12                               // ........*................................................................
        vldrw.32 q5, [r0]                                  // .........*...............................................................
        vqrdmulh.S16 q3, q4, r7                            // ..........*..............................................................
        vsub.U16 q7, q5, q1                                // ...........*.............................................................
        vmul.S16 q4, q4, r6                                // ............*............................................................
        vadd.U16 q1, q5, q1                                // .............*...........................................................
        vmla.S16 q4, q3, r12                               // ..............*..........................................................
        mov r14, #4                                        // ...............*.........................................................
        vadd.U16 q3, q7, q4                                // ................*........................................................
        vmul.S16 q0, q2, r4                                // .................*.......................................................
        vstrw.U32 q3, [r1], #16                            // ..................*......................................................
        vqrdmulh.S16 q2, q2, r5                            // ...................*.....................................................
        vsub.U16 q7, q7, q4                                // ....................*....................................................
        vmla.S16 q0, q2, r12                               // .....................*...................................................
        vstrw.U32 q7, [r1, #(2*64 - 16)]                   // ......................*..................................................
        vadd.U16 q7, q1, q0                                // .......................*.................................................
        vstrw.U32 q7, [r0], #16                            // ........................*................................................
        vsub.U16 q7, q1, q0                                // .........................*...............................................
        vstrw.U32 q7, [r0, #(2*64 - 16)]                   // ..........................*..............................................
        restore r0, STACK0                                 // ...........................*.............................................
        ldrd r1, r9, [r11], #(7*8)                         // ............................*............................................
        vldrw.32 q7, [r0, #64]                             // .............................*...........................................
        vmul.S16 q6, q7, r1                                // ..............................*..........................................
        vldrw.32 q3, [r0]                                  // ...............................*.........................................
        vqrdmulh.S16 q1, q7, r9                            // ................................*........................................
        vldrw.32 q7, [r0, #16]                             // .................................*.......................................
        vmla.S16 q6, q1, r12                               // ..................................*......................................
        vldrw.32 q5, [r0, #80]                             // ...................................*.....................................
        vsub.U16 q2, q3, q6                                // ....................................*....................................
        vmul.S16 q4, q5, r1                                // .....................................*...................................
        vadd.U16 q1, q3, q6                                // ......................................*..................................
        vqrdmulh.S16 q5, q5, r9                            // .......................................*.................................
        qsave QSTACK4, q2                                  // ........................................*................................
        vmla.S16 q4, q5, r12                               // .........................................*...............................
        vldrw.32 q2, [r0, #96]                             // ..........................................*..............................
        vmul.S16 q5, q2, r1                                // ...........................................*.............................
        vsub.U16 q6, q7, q4                                // ............................................*............................
        vqrdmulh.S16 q2, q2, r9                            // .............................................*...........................
        vadd.U16 q3, q7, q4                                // ..............................................*..........................
        vmla.S16 q5, q2, r12                               // ...............................................*.........................
        vldrw.32 q7, [r0, #112]                            // ................................................*........................
        vmul.S16 q0, q7, r1                                // .................................................*.......................
        qsave QSTACK5, q6                                  // ..................................................*......................
        vqrdmulh.S16 q7, q7, r9                            // ...................................................*.....................
        vldrw.32 q2, [r0, #32]                             // ....................................................*....................
        vmla.S16 q0, q7, r12                               // .....................................................*...................
        ldrd r10, r9, [r11, #((-7 + POS_ROOT_1)*8)]        // ......................................................*..................
        vadd.U16 q7, q2, q5                                // .......................................................*.................
        vmul.S16 q4, q7, r10                               // ........................................................*................
        vsub.U16 q2, q2, q5                                // .........................................................*...............
        vqrdmulh.S16 q7, q7, r9                            // ..........................................................*..............
        vldrw.32 q5, [r0, #48]                             // ...........................................................*.............
        vmla.S16 q4, q7, r12                               // ............................................................*............
        vadd.U16 q7, q5, q0                                // .............................................................*...........
        vmul.S16 q6, q7, r10                               // ..............................................................*..........
        qsave QSTACK6, q2                                  // ...............................................................*.........
        vqrdmulh.S16 q2, q7, r9                            // ................................................................*........
        vsub.U16 q7, q5, q0                                // .................................................................*.......
        vmla.S16 q6, q2, r12                               // ..................................................................*......
        ldrd r8, r4, [r11, #((-7 + POS_ROOT_2)*8)]         // ...................................................................*.....
        vadd.U16 q5, q3, q6                                // ....................................................................*....
        vmul.S16 q0, q5, r8                                // .....................................................................*...
        vsub.U16 q2, q1, q4                                // ......................................................................*..
        sub r14, r14, #1                                   // .......................................................................*.
        vqrdmulh.S16 q5, q5, r4                            // ........................................................................*

                                                           // --------------------------- cycle (expected) --------------------------->
                                                           // 0                        25                       50
                                                           // |------------------------|------------------------|----------------------
        // vqrdmulh.S16 q7, q4, r3                         // *........................................................................
        // vldrw.32 q6, [r0, #(2*64)]                      // .*.......................................................................
        // vmla.S16 q5, q7, r12                            // ..*......................................................................
        // vldrw.32 q2, [r1]                               // ...*.....................................................................
        // vqrdmulh.S16 q1, q2, r3                         // ....*....................................................................
        // vsub.U16 q4, q6, q5                             // .....*...................................................................
        // vqrdmulh.S16 q0, q4, r7                         // ..........*..............................................................
        // vadd.U16 q3, q6, q5                             // .......*.................................................................
        // vmul.S16 q5, q2, r2                             // ......*..................................................................
        // vldrw.32 q7, [r0]                               // .........*...............................................................
        // vmla.S16 q5, q1, r12                            // ........*................................................................
        // vmul.S16 q6, q4, r6                             // ............*............................................................
        // vsub.U16 q4, q7, q5                             // ...........*.............................................................
        // vmla.S16 q6, q0, r12                            // ..............*..........................................................
        // vadd.U16 q1, q7, q5                             // .............*...........................................................
        // vqrdmulh.S16 q2, q3, r5                         // ...................*.....................................................
        // vadd.U16 q5, q4, q6                             // ................*........................................................
        // vmul.S16 q0, q3, r4                             // .................*.......................................................
        // vstrw.U32 q5, [r1], #16                         // ..................*......................................................
        // vsub.U16 q5, q4, q6                             // ....................*....................................................
        // vmla.S16 q0, q2, r12                            // .....................*...................................................
        // vstrw.U32 q5, [r1, #(2*64 - 16)]                // ......................*..................................................
        // vsub.U16 q5, q1, q0                             // .........................*...............................................
        // vstrw.U32 q5, [r0, #(2*64 - 16)]                // ..........................*..............................................
        // vadd.U16 q5, q1, q0                             // .......................*.................................................
        // vstrw.U32 q5, [r0], #16                         // ........................*................................................
        // restore r0, STACK0                              // ...........................*.............................................
        // mov r14, #4                                     // ...............*.........................................................
        // ldrd r9, r6, [r11], #(7*8)                      // ............................*............................................
        // vldrw.32 q5, [r0, #64]                          // .............................*...........................................
        // vmul.S16 q7, q5, r9                             // ..............................*..........................................
        // vldrw.32 q1, [r0]                               // ...............................*.........................................
        // vqrdmulh.S16 q5, q5, r6                         // ................................*........................................
        // vldrw.32 q4, [r0, #16]                          // .................................*.......................................
        // vmla.S16 q7, q5, r12                            // ..................................*......................................
        // vldrw.32 q0, [r0, #80]                          // ...................................*.....................................
        // vsub.U16 q6, q1, q7                             // ....................................*....................................
        // vmul.S16 q5, q0, r9                             // .....................................*...................................
        // vadd.U16 q1, q1, q7                             // ......................................*..................................
        // vqrdmulh.S16 q0, q0, r6                         // .......................................*.................................
        // qsave QSTACK4, q6                               // ........................................*................................
        // vmla.S16 q5, q0, r12                            // .........................................*...............................
        // vldrw.32 q0, [r0, #96]                          // ..........................................*..............................
        // vmul.S16 q7, q0, r9                             // ...........................................*.............................
        // vsub.U16 q6, q4, q5                             // ............................................*............................
        // vqrdmulh.S16 q0, q0, r6                         // .............................................*...........................
        // vadd.U16 q3, q4, q5                             // ..............................................*..........................
        // vmla.S16 q7, q0, r12                            // ...............................................*.........................
        // vldrw.32 q5, [r0, #112]                         // ................................................*........................
        // vmul.S16 q0, q5, r9                             // .................................................*.......................
        // qsave QSTACK5, q6                               // ..................................................*......................
        // vqrdmulh.S16 q5, q5, r6                         // ...................................................*.....................
        // vldrw.32 q6, [r0, #32]                          // ....................................................*....................
        // vmla.S16 q0, q5, r12                            // .....................................................*...................
        // ldrd r8, r6, [r11, #((-7 + POS_ROOT_1)*8)]      // ......................................................*..................
        // vadd.U16 q5, q6, q7                             // .......................................................*.................
        // vmul.S16 q4, q5, r8                             // ........................................................*................
        // vsub.U16 q7, q6, q7                             // .........................................................*...............
        // vqrdmulh.S16 q5, q5, r6                         // ..........................................................*..............
        // vldrw.32 q2, [r0, #48]                          // ...........................................................*.............
        // vmla.S16 q4, q5, r12                            // ............................................................*............
        // vadd.U16 q5, q2, q0                             // .............................................................*...........
        // vmul.S16 q6, q5, r8                             // ..............................................................*..........
        // qsave QSTACK6, q7                               // ...............................................................*.........
        // vqrdmulh.S16 q5, q5, r6                         // ................................................................*........
        // vsub.U16 q7, q2, q0                             // .................................................................*.......
        // vmla.S16 q6, q5, r12                            // ..................................................................*......
        // ldrd r8, r6, [r11, #((-7 + POS_ROOT_2)*8)]      // ...................................................................*.....
        // vadd.U16 q5, q3, q6                             // ....................................................................*....
        // vmul.S16 q0, q5, r8                             // .....................................................................*...
        // vsub.U16 q2, q1, q4                             // ......................................................................*..
        // vqrdmulh.S16 q5, q5, r6                         // ........................................................................*
        // sub r14, r14, #1                                // .......................................................................*.

        layer345_loop:

                                                           // Instructions:    89
                                                           // Expected cycles: 89
                                                           // Expected IPC:    1.00
                                                           //
                                                           // Wall time:     29.38s
                                                           // User time:     29.38s
                                                           //
                                                           // ----------------------------------- cycle (expected) ----------------------------------->
                                                           // 0                        25                       50                       75
                                                           // |------------------------|------------------------|------------------------|-------------
        vsub.U16 q6, q3, q6                                // *........................................................................................
        vmla.S16 q0, q5, r12                               // .*.......................................................................................
        ldrd r9, r6, [r11, #((-7 + POS_ROOT_3)*8)]         // ..*......................................................................................
        vadd.U16 q5, q1, q4                                // ...*.....................................................................................
        vmul.S16 q3, q6, r9                                // ....*....................................................................................
        vsub.U16 q4, q5, q0                                // .....*...................................................................................
        vqrdmulh.S16 q6, q6, r6                            // ......*..................................................................................
        vadd.U16 q1, q5, q0                                // .......*.................................................................................
        vmla.S16 q3, q6, r12                               // ........*................................................................................
        vstrw.U32 q1, [r0], #128                           // .........*...............................................................................
        vsub.U16 q6, q2, q3                                // ..........*..............................................................................
        vstrw.U32 q4, [r0, #(-128+16)]                     // ...........*.............................................................................
        ldrd r8, r9, [r11, #((-7 + POS_ROOT_4)*8)]         // ............*............................................................................
        qrestore q1, QSTACK6                               // .............*...........................................................................
        vmul.S16 q4, q1, r8                                // ..............*..........................................................................
        vadd.U16 q3, q2, q3                                // ...............*.........................................................................
        vstrw.U32 q3, [r0, #(-128+32)]                     // ................*........................................................................
        vqrdmulh.S16 q3, q1, r9                            // .................*.......................................................................
        vstrw.U32 q6, [r0, #(-128+48)]                     // ..................*......................................................................
        vmla.S16 q4, q3, r12                               // ...................*.....................................................................
        qrestore q3, QSTACK4                               // ....................*....................................................................
        vmul.S16 q1, q7, r8                                // .....................*...................................................................
        qrestore q2, QSTACK5                               // ......................*..................................................................
        vqrdmulh.S16 q7, q7, r9                            // .......................*.................................................................
        vsub.U16 q0, q3, q4                                // ........................*................................................................
        vmla.S16 q1, q7, r12                               // .........................*...............................................................
        ldrd r5, r9, [r11, #((-7 + POS_ROOT_5)*8)]         // ..........................*..............................................................
        vadd.U16 q7, q2, q1                                // ...........................*.............................................................
        vmul.S16 q6, q7, r5                                // ............................*............................................................
        vadd.U16 q4, q3, q4                                // .............................*...........................................................
        vqrdmulh.S16 q3, q7, r9                            // ..............................*..........................................................
        vsub.U16 q7, q2, q1                                // ...............................*.........................................................
        vmla.S16 q6, q3, r12                               // ................................*........................................................
        ldrd r3, r9, [r11, #((-7 + POS_ROOT_6)*8)]         // .................................*.......................................................
        vsub.U16 q1, q4, q6                                // ..................................*......................................................
        vmul.S16 q2, q7, r3                                // ...................................*.....................................................
        vadd.U16 q3, q4, q6                                // ....................................*....................................................
        vqrdmulh.S16 q7, q7, r9                            // .....................................*...................................................
        vstrw.U32 q3, [r0, #(-128+64)]                     // ......................................*..................................................
        vmla.S16 q2, q7, r12                               // .......................................*.................................................
        vstrw.U32 q1, [r0, #(-128+80)]                     // ........................................*................................................
        vadd.U16 q7, q0, q2                                // .........................................*...............................................
        vstrw.U32 q7, [r0, #(-128+96)]                     // ..........................................*..............................................
        vsub.U16 q7, q0, q2                                // ...........................................*.............................................
        vstrw.U32 q7, [r0, #(-128+112)]                    // ............................................*............................................
        ldrd r1, r9, [r11], #(7*8)                         // .............................................*...........................................
        vldrw.32 q7, [r0, #64]                             // ..............................................*..........................................
        vmul.S16 q1, q7, r1                                // ...............................................*.........................................
        vldrw.32 q6, [r0]                                  // ................................................*........................................
        vqrdmulh.S16 q7, q7, r9                            // .................................................*.......................................
        vldrw.32 q4, [r0, #16]                             // ..................................................*......................................
        vmla.S16 q1, q7, r12                               // ...................................................*.....................................
        vldrw.32 q7, [r0, #80]                             // ....................................................*....................................
        vsub.U16 q2, q6, q1                                // .....................................................*...................................
        vmul.S16 q3, q7, r1                                // ......................................................*..................................
        vadd.U16 q1, q6, q1                                // .......................................................*.................................
        vqrdmulh.S16 q7, q7, r9                            // ........................................................*................................
        qsave QSTACK4, q2                                  // .........................................................*...............................
        vmla.S16 q3, q7, r12                               // ..........................................................*..............................
        vldrw.32 q7, [r0, #96]                             // ...........................................................*.............................
        vmul.S16 q6, q7, r1                                // ............................................................*............................
        vsub.U16 q2, q4, q3                                // .............................................................*...........................
        vqrdmulh.S16 q7, q7, r9                            // ..............................................................*..........................
        vadd.U16 q3, q4, q3                                // ...............................................................*.........................
        vmla.S16 q6, q7, r12                               // ................................................................*........................
        vldrw.32 q7, [r0, #112]                            // .................................................................*.......................
        vmul.S16 q5, q7, r1                                // ..................................................................*......................
        qsave QSTACK5, q2                                  // ...................................................................*.....................
        vqrdmulh.S16 q7, q7, r9                            // ....................................................................*....................
        vldrw.32 q2, [r0, #32]                             // .....................................................................*...................
        vmla.S16 q5, q7, r12                               // ......................................................................*..................
        ldrd r10, r9, [r11, #((-7 + POS_ROOT_1)*8)]        // .......................................................................*.................
        vadd.U16 q7, q2, q6                                // ........................................................................*................
        vmul.S16 q4, q7, r10                               // .........................................................................*...............
        vsub.U16 q2, q2, q6                                // ..........................................................................*..............
        vqrdmulh.S16 q7, q7, r9                            // ...........................................................................*.............
        vldrw.32 q0, [r0, #48]                             // ............................................................................*............
        vmla.S16 q4, q7, r12                               // .............................................................................*...........
        vadd.U16 q7, q0, q5                                // ..............................................................................*..........
        vmul.S16 q6, q7, r10                               // ...............................................................................*.........
        qsave QSTACK6, q2                                  // ................................................................................*........
        vqrdmulh.S16 q2, q7, r9                            // .................................................................................*.......
        vsub.U16 q7, q0, q5                                // ..................................................................................*......
        vmla.S16 q6, q2, r12                               // ...................................................................................*.....
        ldrd r10, r9, [r11, #((-7 + POS_ROOT_2)*8)]        // ....................................................................................*....
        vadd.U16 q5, q3, q6                                // .....................................................................................*...
        vmul.S16 q0, q5, r10                               // ......................................................................................*..
        vsub.U16 q2, q1, q4                                // .......................................................................................*.
        vqrdmulh.S16 q5, q5, r9                            // ........................................................................................*

                                                           // ----------------------------------- cycle (expected) ----------------------------------->
                                                           // 0                        25                       50                       75
                                                           // |------------------------|------------------------|------------------------|-------------
        // vadd.U16 q1, q1, q4                             // ...*.....................................................................................
        // vmla.S16 q0, q5, r12                            // .*.......................................................................................
        // ldrd r8, r6, [r11, #((-7 + POS_ROOT_3)*8)]      // ..*......................................................................................
        // vsub.U16 q5, q3, q6                             // *........................................................................................
        // vmul.S16 q6, q5, r8                             // ....*....................................................................................
        // vsub.U16 q4, q1, q0                             // .....*...................................................................................
        // vqrdmulh.S16 q5, q5, r6                         // ......*..................................................................................
        // vadd.U16 q0, q1, q0                             // .......*.................................................................................
        // vmla.S16 q6, q5, r12                            // ........*................................................................................
        // vstrw.U32 q0, [r0], #128                        // .........*...............................................................................
        // vsub.U16 q0, q2, q6                             // ..........*..............................................................................
        // vstrw.U32 q4, [r0, #(-128+16)]                  // ...........*.............................................................................
        // ldrd r8, r6, [r11, #((-7 + POS_ROOT_4)*8)]      // ............*............................................................................
        // qrestore q5, QSTACK6                            // .............*...........................................................................
        // vmul.S16 q4, q5, r8                             // ..............*..........................................................................
        // vadd.U16 q3, q2, q6                             // ...............*.........................................................................
        // vstrw.U32 q3, [r0, #(-128+32)]                  // ................*........................................................................
        // vqrdmulh.S16 q5, q5, r6                         // .................*.......................................................................
        // vstrw.U32 q0, [r0, #(-128+48)]                  // ..................*......................................................................
        // vmla.S16 q4, q5, r12                            // ...................*.....................................................................
        // qrestore q2, QSTACK4                            // ....................*....................................................................
        // vmul.S16 q0, q7, r8                             // .....................*...................................................................
        // qrestore q1, QSTACK5                            // ......................*..................................................................
        // vqrdmulh.S16 q5, q7, r6                         // .......................*.................................................................
        // vsub.U16 q3, q2, q4                             // ........................*................................................................
        // vmla.S16 q0, q5, r12                            // .........................*...............................................................
        // ldrd r8, r6, [r11, #((-7 + POS_ROOT_5)*8)]      // ..........................*..............................................................
        // vadd.U16 q5, q1, q0                             // ...........................*.............................................................
        // vmul.S16 q6, q5, r8                             // ............................*............................................................
        // vadd.U16 q2, q2, q4                             // .............................*...........................................................
        // vqrdmulh.S16 q5, q5, r6                         // ..............................*..........................................................
        // vsub.U16 q1, q1, q0                             // ...............................*.........................................................
        // vmla.S16 q6, q5, r12                            // ................................*........................................................
        // ldrd r8, r6, [r11, #((-7 + POS_ROOT_6)*8)]      // .................................*.......................................................
        // vsub.U16 q4, q2, q6                             // ..................................*......................................................
        // vmul.S16 q0, q1, r8                             // ...................................*.....................................................
        // vadd.U16 q6, q2, q6                             // ....................................*....................................................
        // vqrdmulh.S16 q5, q1, r6                         // .....................................*...................................................
        // vstrw.U32 q6, [r0, #(-128+64)]                  // ......................................*..................................................
        // vmla.S16 q0, q5, r12                            // .......................................*.................................................
        // vstrw.U32 q4, [r0, #(-128+80)]                  // ........................................*................................................
        // vadd.U16 q5, q3, q0                             // .........................................*...............................................
        // vstrw.U32 q5, [r0, #(-128+96)]                  // ..........................................*..............................................
        // vsub.U16 q5, q3, q0                             // ...........................................*.............................................
        // vstrw.U32 q5, [r0, #(-128+112)]                 // ............................................*............................................
        // ldrd r9, r6, [r11], #(7*8)                      // .............................................*...........................................
        // vldrw.32 q5, [r0, #64]                          // ..............................................*..........................................
        // vmul.S16 q7, q5, r9                             // ...............................................*.........................................
        // vldrw.32 q1, [r0]                               // ................................................*........................................
        // vqrdmulh.S16 q5, q5, r6                         // .................................................*.......................................
        // vldrw.32 q4, [r0, #16]                          // ..................................................*......................................
        // vmla.S16 q7, q5, r12                            // ...................................................*.....................................
        // vldrw.32 q0, [r0, #80]                          // ....................................................*....................................
        // vsub.U16 q6, q1, q7                             // .....................................................*...................................
        // vmul.S16 q5, q0, r9                             // ......................................................*..................................
        // vadd.U16 q1, q1, q7                             // .......................................................*.................................
        // vqrdmulh.S16 q0, q0, r6                         // ........................................................*................................
        // qsave QSTACK4, q6                               // .........................................................*...............................
        // vmla.S16 q5, q0, r12                            // ..........................................................*..............................
        // vldrw.32 q0, [r0, #96]                          // ...........................................................*.............................
        // vmul.S16 q7, q0, r9                             // ............................................................*............................
        // vsub.U16 q6, q4, q5                             // .............................................................*...........................
        // vqrdmulh.S16 q0, q0, r6                         // ..............................................................*..........................
        // vadd.U16 q3, q4, q5                             // ...............................................................*.........................
        // vmla.S16 q7, q0, r12                            // ................................................................*........................
        // vldrw.32 q5, [r0, #112]                         // .................................................................*.......................
        // vmul.S16 q0, q5, r9                             // ..................................................................*......................
        // qsave QSTACK5, q6                               // ...................................................................*.....................
        // vqrdmulh.S16 q5, q5, r6                         // ....................................................................*....................
        // vldrw.32 q6, [r0, #32]                          // .....................................................................*...................
        // vmla.S16 q0, q5, r12                            // ......................................................................*..................
        // ldrd r8, r6, [r11, #((-7 + POS_ROOT_1)*8)]      // .......................................................................*.................
        // vadd.U16 q5, q6, q7                             // ........................................................................*................
        // vmul.S16 q4, q5, r8                             // .........................................................................*...............
        // vsub.U16 q7, q6, q7                             // ..........................................................................*..............
        // vqrdmulh.S16 q5, q5, r6                         // ...........................................................................*.............
        // vldrw.32 q2, [r0, #48]                          // ............................................................................*............
        // vmla.S16 q4, q5, r12                            // .............................................................................*...........
        // vadd.U16 q5, q2, q0                             // ..............................................................................*..........
        // vmul.S16 q6, q5, r8                             // ...............................................................................*.........
        // qsave QSTACK6, q7                               // ................................................................................*........
        // vqrdmulh.S16 q5, q5, r6                         // .................................................................................*.......
        // vsub.U16 q7, q2, q0                             // ..................................................................................*......
        // vmla.S16 q6, q5, r12                            // ...................................................................................*.....
        // ldrd r8, r6, [r11, #((-7 + POS_ROOT_2)*8)]      // ....................................................................................*....
        // vadd.U16 q5, q3, q6                             // .....................................................................................*...
        // vmul.S16 q0, q5, r8                             // ......................................................................................*..
        // vsub.U16 q2, q1, q4                             // .......................................................................................*.
        // vqrdmulh.S16 q5, q5, r6                         // ........................................................................................*

        le lr, layer345_loop
        layer345_loop_end:
                                                          // Instructions:    53
                                                          // Expected cycles: 53
                                                          // Expected IPC:    1.00
                                                          //
                                                          // Wall time:     1.47s
                                                          // User time:     1.47s
                                                          //
                                                          // ----------------- cycle (expected) ----------------->
                                                          // 0                        25                       50
                                                          // |------------------------|------------------------|--
        ldrd r9, r1, [r11, #((-7 + POS_ROOT_3)*8)]        // *....................................................
        vsub.U16 q3, q3, q6                               // .*...................................................
        vqrdmulh.S16 q6, q3, r1                           // ..*..................................................
        ldrd r6, r8, [r11, #((-7 + POS_ROOT_5)*8)]        // ...*.................................................
        vmul.S16 q3, q3, r9                               // ....*................................................
        vadd.U16 q4, q1, q4                               // .....*...............................................
        vmla.S16 q3, q6, r12                              // ......*..............................................
        ldrd r9, r4, [r11, #((-7 + POS_ROOT_4)*8)]        // .......*.............................................
        vsub.U16 q1, q2, q3                               // ........*............................................
        vmul.S16 q6, q7, r9                               // .........*...........................................
        vadd.U16 q2, q2, q3                               // ..........*..........................................
        vqrdmulh.S16 q3, q7, r4                           // ...........*.........................................
        vstrw.U32 q2, [r0, #(-128+32)]                    // ............*........................................
        vmla.S16 q6, q3, r12                              // .............*.......................................
        qrestore q3, QSTACK5                              // ..............*......................................
        vadd.U16 q7, q3, q6                               // ...............*.....................................
        vmul.S16 q2, q7, r6                               // ................*....................................
        vstrw.U32 q1, [r0, #(-128+48)]                    // .................*...................................
        vqrdmulh.S16 q7, q7, r8                           // ..................*..................................
        vsub.U16 q3, q3, q6                               // ...................*.................................
        vmla.S16 q2, q7, r12                              // ....................*................................
        qrestore q6, QSTACK6                              // .....................*...............................
        vqrdmulh.S16 q1, q6, r4                           // ......................*..............................
        restore r1, STACK0                                // .......................*.............................
        vmul.S16 q7, q6, r9                               // ........................*............................
        ldrd r5, r9, [r11, #((-7 + POS_ROOT_6)*8)]        // .........................*...........................
        vmla.S16 q7, q1, r12                              // ..........................*..........................
        qrestore q1, QSTACK4                              // ...........................*.........................
        vadd.U16 q6, q1, q7                               // ............................*........................
        vmla.S16 q0, q5, r12                              // .............................*.......................
        vsub.U16 q5, q6, q2                               // ..............................*......................
        vstrw.U32 q5, [r0, #(-128+80)]                    // ...............................*.....................
        vadd.U16 q2, q6, q2                               // ................................*....................
        vstrw.U32 q2, [r0, #(-128+64)]                    // .................................*...................
        vadd.U16 q6, q4, q0                               // ..................................*..................
        vstrw.U32 q6, [r0], #128                          // ...................................*.................
        vsub.U16 q5, q4, q0                               // ....................................*................
        vstrw.U32 q5, [r0, #(-128+16)]                    // .....................................*...............
        vsub.U16 q2, q1, q7                               // ......................................*..............
        vld40.32 {q4, q5, q6, q7}, [r1]                   // .......................................*.............
        vqrdmulh.S16 q1, q3, r9                           // ........................................*............
        vld41.32 {q4, q5, q6, q7}, [r1]                   // .........................................*...........
        vmul.S16 q3, q3, r5                               // ..........................................*..........
        mov r14, #8                                       // ...........................................*.........
        vmla.S16 q3, q1, r12                              // ............................................*........
        vld42.32 {q4, q5, q6, q7}, [r1]                   // .............................................*.......
        vsub.U16 q0, q2, q3                               // ..............................................*......
        sub r14, r14, #1                                  // ...............................................*.....
        vadd.U16 q2, q2, q3                               // ................................................*....
        vstrw.U32 q0, [r0, #(-128+112)]                   // .................................................*...
        vld43.32 {q4, q5, q6, q7}, [r1]!                  // ..................................................*..
        vstrw.U32 q2, [r0, #(-128+96)]                    // ...................................................*.
        vldrh.16 q0, [r11], #+96                          // ....................................................*

                                                           // ----------------- cycle (expected) ----------------->
                                                           // 0                        25                       50
                                                           // |------------------------|------------------------|--
        // vadd.U16 q1, q1, q4                             // .....*...............................................
        // vmla.S16 q0, q5, r12                            // .............................*.......................
        // ldrd r8, r6, [r11, #((-7 + POS_ROOT_3)*8)]      // *....................................................
        // vsub.U16 q5, q3, q6                             // .*...................................................
        // vmul.S16 q6, q5, r8                             // ....*................................................
        // vsub.U16 q4, q1, q0                             // ....................................*................
        // vqrdmulh.S16 q5, q5, r6                         // ..*..................................................
        // vadd.U16 q0, q1, q0                             // ..................................*..................
        // vmla.S16 q6, q5, r12                            // ......*..............................................
        // vstrw.U32 q0, [r0], #128                        // ...................................*.................
        // vsub.U16 q0, q2, q6                             // ........*............................................
        // vstrw.U32 q4, [r0, #(-128+16)]                  // .....................................*...............
        // ldrd r8, r6, [r11, #((-7 + POS_ROOT_4)*8)]      // .......*.............................................
        // qrestore q5, QSTACK6                            // .....................*...............................
        // vmul.S16 q4, q5, r8                             // ........................*............................
        // vadd.U16 q3, q2, q6                             // ..........*..........................................
        // vstrw.U32 q3, [r0, #(-128+32)]                  // ............*........................................
        // vqrdmulh.S16 q5, q5, r6                         // ......................*..............................
        // vstrw.U32 q0, [r0, #(-128+48)]                  // .................*...................................
        // vmla.S16 q4, q5, r12                            // ..........................*..........................
        // qrestore q2, QSTACK4                            // ...........................*.........................
        // vmul.S16 q0, q7, r8                             // .........*...........................................
        // qrestore q1, QSTACK5                            // ..............*......................................
        // vqrdmulh.S16 q5, q7, r6                         // ...........*.........................................
        // vsub.U16 q3, q2, q4                             // ......................................*..............
        // vmla.S16 q0, q5, r12                            // .............*.......................................
        // ldrd r8, r6, [r11, #((-7 + POS_ROOT_5)*8)]      // ...*.................................................
        // vadd.U16 q5, q1, q0                             // ...............*.....................................
        // vmul.S16 q6, q5, r8                             // ................*....................................
        // vadd.U16 q2, q2, q4                             // ............................*........................
        // vqrdmulh.S16 q5, q5, r6                         // ..................*..................................
        // vsub.U16 q1, q1, q0                             // ...................*.................................
        // vmla.S16 q6, q5, r12                            // ....................*................................
        // ldrd r8, r6, [r11, #((-7 + POS_ROOT_6)*8)]      // .........................*...........................
        // vsub.U16 q4, q2, q6                             // ..............................*......................
        // vmul.S16 q0, q1, r8                             // ..........................................*..........
        // vadd.U16 q6, q2, q6                             // ................................*....................
        // vqrdmulh.S16 q5, q1, r6                         // ........................................*............
        // vstrw.U32 q6, [r0, #(-128+64)]                  // .................................*...................
        // vmla.S16 q0, q5, r12                            // ............................................*........
        // vstrw.U32 q4, [r0, #(-128+80)]                  // ...............................*.....................
        // vadd.U16 q5, q3, q0                             // ................................................*....
        // vstrw.U32 q5, [r0, #(-128+96)]                  // ...................................................*.
        // vsub.U16 q5, q3, q0                             // ..............................................*......
        // vstrw.U32 q5, [r0, #(-128+112)]                 // .................................................*...
        // restore r1, STACK0                              // .......................*.............................
        // mov r14, #8                                     // ...........................................*.........
        // vld40.32 {q4, q5, q6, q7}, [r1]                 // .......................................*.............
        // vld41.32 {q4, q5, q6, q7}, [r1]                 // .........................................*...........
        // vldrh.16 q0, [r11], #+96                        // ....................................................*
        // vld42.32 {q4, q5, q6, q7}, [r1]                 // .............................................*.......
        // vld43.32 {q4, q5, q6, q7}, [r1]!                // ..................................................*..
        // sub r14, r14, #1                                // ...............................................*.....

        layer67_loop:

                                                // Instructions:    34
                                                // Expected cycles: 35
                                                // Expected IPC:    0.97
                                                //
                                                // Wall time:     22.01s
                                                // User time:     22.01s
                                                //
                                                // -------- cycle (expected) -------->
                                                // 0                        25
                                                // |------------------------|---------
        vmul.S16 q3, q7, q0                     // *..................................
        vldrh.16 q2, [r11, #(+16-96)]           // .*.................................
        vqrdmulh.S16 q1, q7, q2                 // ..*................................
        vldrh.16 q7, [r11, #(48 - 96)]          // ...*...............................
        vmla.S16 q3, q1, r12                    // ....*..............................
        vqrdmulh.S16 q2, q6, q2                 // ......*............................
        vadd.U16 q1, q5, q3                     // .......*...........................
        vmul.S16 q0, q6, q0                     // ........*..........................
        vsub.U16 q3, q5, q3                     // .........*.........................
        vmla.S16 q0, q2, r12                    // ..........*........................
        vldrh.16 q2, [r11, #(32 - 96)]          // ...........*.......................
        vmul.S16 q5, q1, q2                     // ............*......................
        vsub.U16 q2, q4, q0                     // .............*.....................
        vqrdmulh.S16 q6, q1, q7                 // ..............*....................
        vadd.U16 q7, q4, q0                     // ...............*...................
        vmla.S16 q5, q6, r12                    // ................*..................
        vldrh.16 q1, [r11, #(64-96)]            // .................*.................
        vsub.U16 q6, q7, q5                     // ..................*................
        vstrw.U32 q6, [r1, #-48]                // ...................*...............
        vadd.U16 q0, q7, q5                     // ....................*..............
        vld40.32 {q4, q5, q6, q7}, [r1]         // .....................e.............
        vmul.S16 q1, q3, q1                     // ......................*............
        vld41.32 {q4, q5, q6, q7}, [r1]         // .......................e...........
        vstrw.U32 q0, [r1, #-64]                // ........................*..........
        vldrh.16 q0, [r11, #(80-96)]            // .........................*.........
        vqrdmulh.S16 q3, q3, q0                 // ..........................*........
        vld42.32 {q4, q5, q6, q7}, [r1]         // ...........................e.......
        vmla.S16 q1, q3, r12                    // ............................*......
        vldrh.16 q0, [r11], #+96                // .............................e.....
        vadd.U16 q3, q2, q1                     // ..............................*....
        vld43.32 {q4, q5, q6, q7}, [r1]!        // ...............................e...
        vstrw.U32 q3, [r1, #-32]                // ................................*..
        vsub.U16 q3, q2, q1                     // .................................*.
        vstrw.U32 q3, [r1, #-16]                // ..................................*

                                                  // --------------- cycle (expected) --------------->
                                                  // 0                        25
                                                  // |------------------------|-----------------------
        // vld40.32 {q0, q1, q2, q3}, [r1]        // e.............'....................~.............
        // vld41.32 {q0, q1, q2, q3}, [r1]        // ..e...........'......................~...........
        // vld42.32 {q0, q1, q2, q3}, [r1]        // ......e.......'..........................~.......
        // vld43.32 {q0, q1, q2, q3}, [r1]!       // ..........e...'..............................~...
        // vldrh.16 q5,    [r11], #+96            // ........e.....'............................~.....
        // vldrh.16 q6, [r11, #(+16-96)]          // ..............'*.................................
        // vmul.s16       q7,  q2, q5             // ..............'.......*..........................
        // vqrdmulh.s16   q2,  q2, q6             // ..............'.....*............................
        // vmla.s16       q7,  q2, r12            // ..............'.........*........................
        // vsub.u16       q2,    q0, q7           // ..............'............*.....................
        // vadd.u16       q0,    q0, q7           // ..............'..............*...................
        // vmul.s16       q7,  q3, q5             // ..............*..................................
        // vqrdmulh.s16   q3,  q3, q6             // ..............'.*................................
        // vmla.s16       q7,  q3, r12            // ..............'...*..............................
        // vsub.u16       q3,    q1, q7           // ..............'........*.........................
        // vadd.u16       q1,    q1, q7           // ..............'......*...........................
        // vldrh.16 q5,    [r11, #(32 - 96)]      // ..............'..........*.......................
        // vldrh.16 q6, [r11, #(48 - 96)]         // ..............'..*...............................
        // vmul.s16       q7,  q1, q5             // ..............'...........*......................
        // vqrdmulh.s16   q1,  q1, q6             // ..............'.............*....................
        // vmla.s16       q7,  q1, r12            // ..............'...............*..................
        // vsub.u16       q1,    q0, q7           // ..............'.................*................
        // vadd.u16       q0,    q0, q7           // ..............'...................*..............
        // vldrh.16 q5,    [r11, #(64-96)]        // ..............'................*.................
        // vldrh.16 q6, [r11, #(80-96)]           // ....~.........'........................*.........
        // vmul.s16       q7,  q3, q5             // .~............'.....................*............
        // vqrdmulh.s16   q3,  q3, q6             // .....~........'.........................*........
        // vmla.s16       q7,  q3, r12            // .......~......'...........................*......
        // vsub.u16       q3,    q2, q7           // ............~.'................................*.
        // vadd.u16       q2,    q2, q7           // .........~....'.............................*....
        // vstrw.u32 q0, [r1, #-64]               // ...~..........'.......................*..........
        // vstrw.u32 q1, [r1, #-48]               // ..............'..................*...............
        // vstrw.u32 q2, [r1, #-32]               // ...........~..'...............................*..
        // vstrw.u32 q3, [r1, #-16]               // .............~'.................................*

        le lr, layer67_loop
                                              // Instructions:    29
                                              // Expected cycles: 30
                                              // Expected IPC:    0.97
                                              //
                                              // Wall time:     0.30s
                                              // User time:     0.30s
                                              //
                                              // ----- cycle (expected) ------>
                                              // 0                        25
                                              // |------------------------|----
        vmul.S16 q3, q7, q0                   // *.............................
        vldrh.16 q1, [r11, #(+16-96)]         // .*............................
        vqrdmulh.S16 q7, q7, q1               // ..*...........................
        vmla.S16 q3, q7, r12                  // ....*.........................
        vldrh.16 q7, [r11, #(32 - 96)]        // .....*........................
        vadd.U16 q2, q5, q3                   // ......*.......................
        vmul.S16 q7, q2, q7                   // .......*......................
        vsub.U16 q3, q5, q3                   // ........*.....................
        vmul.S16 q0, q6, q0                   // .........*....................
        vldrh.16 q5, [r11, #(48 - 96)]        // ..........*...................
        vqrdmulh.S16 q1, q6, q1               // ...........*..................
        vldrh.16 q6, [r11, #(80-96)]          // ............*.................
        vmla.S16 q0, q1, r12                  // .............*................
        vldrh.16 q1, [r11, #(64-96)]          // ..............*...............
        vqrdmulh.S16 q2, q2, q5               // ...............*..............
        vadd.U16 q5, q4, q0                   // ................*.............
        vmla.S16 q7, q2, r12                  // .................*............
        vsub.U16 q2, q4, q0                   // ..................*...........
        vqrdmulh.S16 q6, q3, q6               // ...................*..........
        vadd.U16 q4, q5, q7                   // ....................*.........
        vmul.S16 q0, q3, q1                   // .....................*........
        vstrw.U32 q4, [r1, #-64]              // ......................*.......
        vmla.S16 q0, q6, r12                  // .......................*......
        vsub.U16 q1, q5, q7                   // ........................*.....
        vstrw.U32 q1, [r1, #-48]              // .........................*....
        vsub.U16 q5, q2, q0                   // ..........................*...
        vstrw.U32 q5, [r1, #-16]              // ...........................*..
        vadd.U16 q2, q2, q0                   // ............................*.
        vstrw.U32 q2, [r1, #-32]              // .............................*

                                               // ------ cycle (expected) ------>
                                               // 0                        25
                                               // |------------------------|-----
        // vmul.S16 q3, q7, q0                 // *..............................
        // vldrh.16 q2, [r11, #(+16-96)]       // .*.............................
        // vqrdmulh.S16 q1, q7, q2             // ..*............................
        // vldrh.16 q7, [r11, #(48 - 96)]      // ..........*....................
        // vmla.S16 q3, q1, r12                // ....*..........................
        // vqrdmulh.S16 q2, q6, q2             // ...........*...................
        // vadd.U16 q1, q5, q3                 // ......*........................
        // vmul.S16 q0, q6, q0                 // .........*.....................
        // vsub.U16 q3, q5, q3                 // ........*......................
        // vmla.S16 q0, q2, r12                // .............*.................
        // vldrh.16 q2, [r11, #(32 - 96)]      // .....*.........................
        // vmul.S16 q5, q1, q2                 // .......*.......................
        // vsub.U16 q2, q4, q0                 // ..................*............
        // vqrdmulh.S16 q6, q1, q7             // ...............*...............
        // vadd.U16 q7, q4, q0                 // ................*..............
        // vmla.S16 q5, q6, r12                // .................*.............
        // vldrh.16 q1, [r11, #(64-96)]        // ..............*................
        // vsub.U16 q6, q7, q5                 // ........................*......
        // vstrw.U32 q6, [r1, #-48]            // .........................*.....
        // vadd.U16 q0, q7, q5                 // ....................*..........
        // vmul.S16 q1, q3, q1                 // .....................*.........
        // vstrw.U32 q0, [r1, #-64]            // ......................*........
        // vldrh.16 q0, [r11, #(80-96)]        // ............*..................
        // vqrdmulh.S16 q3, q3, q0             // ...................*...........
        // vmla.S16 q1, q3, r12                // .......................*.......
        // vadd.U16 q3, q2, q1                 // ............................*..
        // vstrw.U32 q3, [r1, #-32]            // .............................*.
        // vsub.U16 q3, q2, q1                 // ..........................*....
        // vstrw.U32 q3, [r1, #-16]            // ...........................*...


        add sp, sp, #STACK_SIZE

        align_stack_undo
        // Restore MVE vector registers
        vpop {d8-d15}
        // Restore GPRs
        pop {r4-r11,lr}
        bx lr
