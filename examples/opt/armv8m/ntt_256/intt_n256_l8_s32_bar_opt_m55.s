
///
/// Copyright (c) 2021 Arm Limited
/// Copyright (c) 2022 Hanno Becker
/// Copyright (c) 2023 Amin Abdulrahman, Matthias Kannwischer
/// SPDX-License-Identifier: MIT
///
/// Permission is hereby granted, free of charge, to any person obtaining a copy
/// of this software and associated documentation files (the "Software"), to deal
/// in the Software without restriction, including without limitation the rights
/// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
/// copies of the Software, and to permit persons to whom the Software is
/// furnished to do so, subject to the following conditions:
///
/// The above copyright notice and this permission notice shall be included in all
/// copies or substantial portions of the Software.
///
/// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
/// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
/// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
/// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
/// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
/// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
/// SOFTWARE.
///

#define INVNTT_REDUCE_AFTER_L56
#define INVNTT_REDUCE_AFTER_L34

.data
roots_inv:
#include "intt_n256_l8_s32_twiddles.s"
.text

// Barrett multiplication
.macro mulmod dst, src, const, const_twisted
        vmul.s32       \dst,  \src, \const
        vqrdmulh.s32   \src,  \src, \const_twisted
        vmla.s32       \dst,  \src, modulus
.endm

.macro gs_butterfly a, b, root, root_twisted
        vsub.u32       tmp, \a,  \b
        vadd.u32       \a,  \a,  \b
        mulmod         \b,  tmp, \root, \root_twisted
.endm

.align 4
roots_addr: .word roots_inv
.syntax unified
.type invntt_n256_u32_33556993_28678040_complete_manual, %function
.global invntt_n256_u32_33556993_28678040_complete_manual
invntt_n256_u32_33556993_28678040_complete_manual:

        push {r4-r11,lr}
        // Save MVE vector registers
        vpush {d8-d15}

        modulus     .req r12
        root_ptr    .req r11

        .equ modulus_const, -33556993
        movw modulus, #:lower16:modulus_const
        movt modulus, #:upper16:modulus_const
        ldr  root_ptr, roots_addr

        in .req r0

        data0 .req q0
        data1 .req q1
        data2 .req q2
        data3 .req q3

        root0         .req q5
        root0_twisted .req q6
        root1         .req q5
        root1_twisted .req q6
        root2         .req q5
        root2_twisted .req q6


        tmp .req q4

        // Layers 7,8

        mov lr, #16
                                        // Instructions:    3
                                        // Expected cycles: 5
                                        // Expected IPC:    0.60
                                        //
                                        // Wall time:     0.00s
                                        // User time:     0.00s
                                        //
                                        // ----- cycle (expected) ------>
                                        // 0                        25
                                        // |------------------------|----
        vldrw.U32 q6, [r0, #16]         // *.............................
        vldrw.U32 q3, [r11, #32]        // ..*...........................
        vldrw.U32 q1, [r0]              // ....*.........................

                                         // ------ cycle (expected) ------>
                                         // 0                        25
                                         // |------------------------|-----
        // vldrw.U32 q1, [r0]            // ....*..........................
        // vldrw.U32 q3, [r11, #32]      // ..*............................
        // vldrw.U32 q6, [r0, #16]       // *..............................

        sub lr, lr, #1
.p2align 2
layer78_loop:
                                            // Instructions:    34
                                            // Expected cycles: 34
                                            // Expected IPC:    1.00
                                            //
                                            // Wall time:     2.42s
                                            // User time:     2.42s
                                            //
                                            // ------- cycle (expected) -------->
                                            // 0                        25
                                            // |------------------------|--------
        vsub.U32 q0, q1, q6                 // *.................................
        vmul.S32 q2, q0, q3                 // .*................................
        vldrw.U32 q4, [r11, #48]            // ..*...............................
        vqrdmulh.S32 q5, q0, q4             // ...*..............................
        vldrw.U32 q4, [r0, #32]             // ....*.............................
        vmla.S32 q2, q5, r12                // .....*............................
        vldrw.U32 q3, [r0, #48]             // ......*...........................
        vsub.U32 q5, q4, q3                 // .......*..........................
        vldrw.U32 q7, [r11, #80]            // ........*.........................
        vadd.U32 q4, q4, q3                 // .........*........................
        vldrw.U32 q3, [r11], #(3*32)        // ..........*.......................
        vqrdmulh.S32 q0, q5, q7             // ...........*......................
        vldrw.U32 q7, [r11, #-32]           // ............*.....................
        vadd.U32 q6, q1, q6                 // .............*....................
        vmul.S32 q7, q5, q7                 // ..............*...................
        vadd.U32 q5, q6, q4                 // ...............*..................
        vmla.S32 q7, q0, r12                // ................*.................
        vldrw.U32 q1, [r0, #64]             // .................e................
        vsub.U32 q0, q2, q7                 // ..................*...............
        vstrw.U32 q5, [r0], #64             // ...................*..............
        vadd.U32 q5, q2, q7                 // ....................*.............
        vmul.S32 q7, q0, q3                 // .....................*............
        vldrw.U32 q2, [r11, #-80]           // ......................*...........
        vqrdmulh.S32 q0, q0, q2             // .......................*..........
        vstrw.U32 q5, [r0, #-48]            // ........................*.........
        vmla.S32 q7, q0, r12                // .........................*........
        vstrw.U32 q7, [r0, #-16]            // ..........................*.......
        vsub.U32 q5, q6, q4                 // ...........................*......
        vmul.S32 q0, q5, q3                 // ............................*.....
        vldrw.U32 q3, [r11, #32]            // .............................e....
        vqrdmulh.S32 q7, q5, q2             // ..............................*...
        vldrw.U32 q6, [r0, #16]             // ...............................e..
        vmla.S32 q0, q7, r12                // ................................*.
        vstrw.U32 q0, [r0, #-32]            // .................................*

                                                     // ---------------- cycle (expected) ---------------->
                                                     // 0                        25
                                                     // |------------------------|-------------------------
        // vldrw.u32 q0, [r0]                        // e................'................~................
        // vldrw.u32 q1, [r0, #(4*4*1)]              // ..............e..'..............................~..
        // vldrw.u32 q2, [r0, #(4*4*2)]              // .................'...*.............................
        // vldrw.u32 q3, [r0, #(4*4*3)]              // .................'.....*...........................
        // vldrw.u32 q5,         [r11, #(32)]        // ............e....'............................~....
        // vldrw.u32 q6, [r11, #(32+16)]             // .................'.*...............................
        // vsub.u32       q4, q0,  q1                // .................*.................................
        // vadd.u32       q0,  q0,  q1               // .................'............*....................
        // vmul.s32       q1,  q4, q5                // .................'*................................
        // vqrdmulh.s32   q4,  q4, q6                // .................'..*..............................
        // vmla.s32       q1,  q4, r12               // .................'....*............................
        // vldrw.u32 q5,         [r11, #(64)]        // .................'...........*.....................
        // vldrw.u32 q6, [r11, #(64+16)]             // .................'.......*.........................
        // vsub.u32       q4, q2,  q3                // .................'......*..........................
        // vadd.u32       q2,  q2,  q3               // .................'........*........................
        // vmul.s32       q3,  q4, q5                // .................'.............*...................
        // vqrdmulh.s32   q4,  q4, q6                // .................'..........*......................
        // vmla.s32       q3,  q4, r12               // .................'...............*.................
        // vldrw.u32 q5,         [r11], #(3*32)      // .................'.........*.......................
        // vldrw.u32 q6, [r11, #(16 - 3*32)]         // .....~...........'.....................*...........
        // vsub.u32       q4, q0,  q2                // ..........~......'..........................*......
        // vadd.u32       q0,  q0,  q2               // .................'..............*..................
        // vmul.s32       q2,  q4, q5                // ...........~.....'...........................*.....
        // vqrdmulh.s32   q4,  q4, q6                // .............~...'.............................*...
        // vmla.s32       q2,  q4, r12               // ...............~.'...............................*.
        // vsub.u32       q4, q1,  q3                // .~...............'.................*...............
        // vadd.u32       q1,  q1,  q3               // ...~.............'...................*.............
        // vmul.s32       q3,  q4, q5                // ....~............'....................*............
        // vqrdmulh.s32   q4,  q4, q6                // ......~..........'......................*..........
        // vmla.s32       q3,  q4, r12               // ........~........'........................*........
        // vstrw.u32 q0, [r0], #64                   // ..~..............'..................*..............
        // vstrw.u32 q1, [r0, #(4*4*1 - 64)]         // .......~.........'.......................*.........
        // vstrw.u32 q2, [r0, #(4*4*2 - 64)]         // ................~'................................*
        // vstrw.u32 q3, [r0, #(4*4*3 - 64)]         // .........~.......'.........................*.......

        le lr, layer78_loop
                                            // Instructions:    31
                                            // Expected cycles: 31
                                            // Expected IPC:    1.00
                                            //
                                            // Wall time:     0.47s
                                            // User time:     0.47s
                                            //
                                            // ------ cycle (expected) ------>
                                            // 0                        25
                                            // |------------------------|-----
        vadd.U32 q4, q1, q6                 // *..............................
        vldrw.U32 q5, [r11, #48]            // .*.............................
        vsub.U32 q6, q1, q6                 // ..*............................
        vldrw.U32 q2, [r0, #32]             // ...*...........................
        vqrdmulh.S32 q7, q6, q5             // ....*..........................
        vldrw.U32 q5, [r0, #48]             // .....*.........................
        vmul.S32 q3, q6, q3                 // ......*........................
        vadd.U32 q6, q2, q5                 // .......*.......................
        vmla.S32 q3, q7, r12                // ........*......................
        vldrw.U32 q7, [r11, #80]            // .........*.....................
        vadd.U32 q0, q4, q6                 // ..........*....................
        vstrw.U32 q0, [r0], #64             // ...........*...................
        vsub.U32 q1, q2, q5                 // ............*..................
        vqrdmulh.S32 q0, q1, q7             // .............*.................
        vldrw.U32 q2, [r11, #64]            // ..............*................
        vmul.S32 q2, q1, q2                 // ...............*...............
        vsub.U32 q7, q4, q6                 // ................*..............
        vmla.S32 q2, q0, r12                // .................*.............
        vldrw.U32 q4, [r11], #(3*32)        // ..................*............
        vmul.S32 q6, q7, q4                 // ...................*...........
        vsub.U32 q5, q3, q2                 // ....................*..........
        vmul.S32 q1, q5, q4                 // .....................*.........
        vldrw.U32 q0, [r11, #-80]           // ......................*........
        vqrdmulh.S32 q5, q5, q0             // .......................*.......
        vadd.U32 q4, q3, q2                 // ........................*......
        vmla.S32 q1, q5, r12                // .........................*.....
        vstrw.U32 q4, [r0, #-48]            // ..........................*....
        vqrdmulh.S32 q3, q7, q0             // ...........................*...
        vstrw.U32 q1, [r0, #-16]            // ............................*..
        vmla.S32 q6, q3, r12                // .............................*.
        vstrw.U32 q6, [r0, #-32]            // ..............................*

                                             // ------ cycle (expected) ------>
                                             // 0                        25
                                             // |------------------------|-----
        // vsub.U32 q0, q1, q6               // ..*............................
        // vmul.S32 q2, q0, q3               // ......*........................
        // vldrw.U32 q4, [r11, #48]          // .*.............................
        // vqrdmulh.S32 q5, q0, q4           // ....*..........................
        // vldrw.U32 q4, [r0, #32]           // ...*...........................
        // vmla.S32 q2, q5, r12              // ........*......................
        // vldrw.U32 q3, [r0, #48]           // .....*.........................
        // vsub.U32 q5, q4, q3               // ............*..................
        // vldrw.U32 q7, [r11, #80]          // .........*.....................
        // vadd.U32 q4, q4, q3               // .......*.......................
        // vldrw.U32 q3, [r11], #(3*32)      // ..................*............
        // vqrdmulh.S32 q0, q5, q7           // .............*.................
        // vldrw.U32 q7, [r11, #-32]         // ..............*................
        // vadd.U32 q6, q1, q6               // *..............................
        // vmul.S32 q7, q5, q7               // ...............*...............
        // vadd.U32 q5, q6, q4               // ..........*....................
        // vmla.S32 q7, q0, r12              // .................*.............
        // vsub.U32 q0, q2, q7               // ....................*..........
        // vstrw.U32 q5, [r0], #64           // ...........*...................
        // vadd.U32 q5, q2, q7               // ........................*......
        // vmul.S32 q7, q0, q3               // .....................*.........
        // vldrw.U32 q2, [r11, #-80]         // ......................*........
        // vqrdmulh.S32 q0, q0, q2           // .......................*.......
        // vstrw.U32 q5, [r0, #-48]          // ..........................*....
        // vmla.S32 q7, q0, r12              // .........................*.....
        // vstrw.U32 q7, [r0, #-16]          // ............................*..
        // vsub.U32 q5, q6, q4               // ................*..............
        // vmul.S32 q0, q5, q3               // ...................*...........
        // vqrdmulh.S32 q7, q5, q2           // ...........................*...
        // vmla.S32 q0, q7, r12              // .............................*.
        // vstrw.U32 q0, [r0, #-32]          // ..............................*


        sub in, in, #(4*256)

        .unreq root0
        .unreq root0_twisted
        .unreq root1
        .unreq root1_twisted
        .unreq root2
        .unreq root2_twisted

        root0         .req r2
        root0_twisted .req r3
        root1         .req r4
        root1_twisted .req r5
        root2         .req r6
        root2_twisted .req r7

        // Layers 5,6

        mov lr, #16
                                                // Instructions:    5
                                                // Expected cycles: 8
                                                // Expected IPC:    0.62
                                                //
                                                // Wall time:     0.01s
                                                // User time:     0.01s
                                                //
                                                // ----- cycle (expected) ------>
                                                // 0                        25
                                                // |------------------------|----
        vld40.U32 {q3, q4, q5, q6}, [r0]        // *.............................
        vld41.U32 {q3, q4, q5, q6}, [r0]        // ..*...........................
        vld42.U32 {q3, q4, q5, q6}, [r0]        // ....*.........................
        ldrd r4, r6, [r11, #16]                 // ......*.......................
        vld43.U32 {q3, q4, q5, q6}, [r0]        // .......*......................

                                                 // ------ cycle (expected) ------>
                                                 // 0                        25
                                                 // |------------------------|-----
        // vld40.U32 {q3, q4, q5, q6}, [r0]      // *..............................
        // vld41.U32 {q3, q4, q5, q6}, [r0]      // ..*............................
        // ldrd r4, r6, [r11, #16]               // ......*........................
        // vld42.U32 {q3, q4, q5, q6}, [r0]      // ....*..........................
        // vld43.U32 {q3, q4, q5, q6}, [r0]      // .......*.......................

        sub lr, lr, #1
.p2align 2
layer56_loop:
                                                // Instructions:    31
                                                // Expected cycles: 31
                                                // Expected IPC:    1.00
                                                //
                                                // Wall time:     2.48s
                                                // User time:     2.48s
                                                //
                                                // ------ cycle (expected) ------>
                                                // 0                        25
                                                // |------------------------|-----
        vsub.U32 q2, q5, q6                     // *..............................
        vqrdmulh.S32 q7, q2, r6                 // .*.............................
        ldrd r7, r10, [r11, #8]                 // ..*............................
        vmul.S32 q2, q2, r4                     // ...*...........................
        vsub.U32 q1, q3, q4                     // ....*..........................
        vmla.S32 q2, q7, r12                    // .....*.........................
        vadd.U32 q0, q3, q4                     // ......*........................
        vmul.S32 q3, q1, r7                     // .......*.......................
        vadd.U32 q7, q5, q6                     // ........*......................
        vqrdmulh.S32 q6, q1, r10                // .........*.....................
        vadd.U32 q5, q0, q7                     // ..........*....................
        ldrd r8, r3, [r11], #24                 // ...........*...................
        vmla.S32 q3, q6, r12                    // ............*..................
        vstrw.U32 q5, [r0], #(64)               // .............*.................
        vadd.U32 q4, q3, q2                     // ..............*................
        vstrw.U32 q4, [r0, #-48]                // ...............*...............
        vsub.U32 q2, q3, q2                     // ................*..............
        vqrdmulh.S32 q1, q2, r3                 // .................*.............
        vld40.U32 {q3, q4, q5, q6}, [r0]        // ..................e............
        vmul.S32 q2, q2, r8                     // ...................*...........
        vld41.U32 {q3, q4, q5, q6}, [r0]        // ....................e..........
        vmla.S32 q2, q1, r12                    // .....................*.........
        ldrd r4, r6, [r11, #16]                 // ......................e........
        vld42.U32 {q3, q4, q5, q6}, [r0]        // .......................e.......
        vsub.U32 q1, q0, q7                     // ........................*......
        vqrdmulh.S32 q0, q1, r3                 // .........................*.....
        vld43.U32 {q3, q4, q5, q6}, [r0]        // ..........................e....
        vmul.S32 q7, q1, r8                     // ...........................*...
        vstrw.U32 q2, [r0, #-16]                // ............................*..
        vmla.S32 q7, q0, r12                    // .............................*.
        vstrw.U32 q7, [r0, #-32]                // ..............................*

                                                  // ------------ cycle (expected) ------------->
                                                  // 0                        25
                                                  // |------------------------|------------------
        // ldrd r2, r3, [r11], #24                // .............'..........*...................
        // ldrd r4, r5, [r11, #-16]               // .............'.*............................
        // ldrd r6, r7, [r11, #-8]                // ....e........'.....................~........
        // vld40.u32 {q0, q1, q2, q3}, [r0]       // e............'.................~............
        // vld41.u32 {q0, q1, q2, q3}, [r0]       // ..e..........'...................~..........
        // vld42.u32 {q0, q1, q2, q3}, [r0]       // .....e.......'......................~.......
        // vld43.u32 {q0, q1, q2, q3}, [r0]       // ........e....'.........................~....
        // vsub.u32       q4, q0,  q1             // .............'...*..........................
        // vadd.u32       q0,  q0,  q1            // .............'.....*........................
        // vmul.s32       q1,  q4, r4             // .............'......*.......................
        // vqrdmulh.s32   q4,  q4, r5             // .............'........*.....................
        // vmla.s32       q1,  q4, r12            // .............'...........*..................
        // vsub.u32       q4, q2,  q3             // .............*..............................
        // vadd.u32       q2,  q2,  q3            // .............'.......*......................
        // vmul.s32       q3,  q4, r6             // .............'..*...........................
        // vqrdmulh.s32   q4,  q4, r7             // .............'*.............................
        // vmla.s32       q3,  q4, r12            // .............'....*.........................
        // vsub.u32       q4, q0,  q2             // ......~......'.......................*......
        // vadd.u32       q0,  q0,  q2            // .............'.........*....................
        // vmul.s32       q2,  q4, r2             // .........~...'..........................*...
        // vqrdmulh.s32   q4,  q4, r3             // .......~.....'........................*.....
        // vmla.s32       q2,  q4, r12            // ...........~.'............................*.
        // vsub.u32       q4, q1,  q3             // .............'...............*..............
        // vadd.u32       q1,  q1,  q3            // .............'.............*................
        // vmul.s32       q3,  q4, r2             // .~...........'..................*...........
        // vqrdmulh.s32   q4,  q4, r3             // .............'................*.............
        // vmla.s32       q3,  q4, r12            // ...~.........'....................*.........
        // vstrw.u32 q0, [r0], #(64)              // .............'............*.................
        // vstrw.u32 q1, [r0, #(4*4*1 - 64)]      // .............'..............*...............
        // vstrw.u32 q2, [r0, #(4*4*2 - 64)]      // ............~'.............................*
        // vstrw.u32 q3, [r0, #(4*4*3 - 64)]      // ..........~..'...........................*..

        le lr, layer56_loop
                                         // Instructions:    26
                                         // Expected cycles: 26
                                         // Expected IPC:    1.00
                                         //
                                         // Wall time:     0.25s
                                         // User time:     0.25s
                                         //
                                         // ----- cycle (expected) ------>
                                         // 0                        25
                                         // |------------------------|----
        vsub.U32 q7, q5, q6              // *.............................
        vmul.S32 q0, q7, r4              // .*............................
        vadd.U32 q5, q5, q6              // ..*...........................
        ldrd r8, r3, [r11, #8]           // ...*..........................
        vqrdmulh.S32 q7, q7, r6          // ....*.........................
        vsub.U32 q6, q3, q4              // .....*........................
        vqrdmulh.S32 q2, q6, r3          // ......*.......................
        vadd.U32 q4, q3, q4              // .......*......................
        vmla.S32 q0, q7, r12             // ........*.....................
        ldrd r4, r10, [r11], #24         // .........*....................
        vmul.S32 q1, q6, r8              // ..........*...................
        vsub.U32 q7, q4, q5              // ...........*..................
        vqrdmulh.S32 q6, q7, r10         // ............*.................
        vadd.U32 q4, q4, q5              // .............*................
        vmla.S32 q1, q2, r12             // ..............*...............
        vstrw.U32 q4, [r0], #(64)        // ...............*..............
        vmul.S32 q4, q7, r4              // ................*.............
        vsub.U32 q3, q1, q0              // .................*............
        vqrdmulh.S32 q5, q3, r10         // ..................*...........
        vadd.U32 q2, q1, q0              // ...................*..........
        vmla.S32 q4, q6, r12             // ....................*.........
        vstrw.U32 q4, [r0, #-32]         // .....................*........
        vmul.S32 q4, q3, r4              // ......................*.......
        vstrw.U32 q2, [r0, #-48]         // .......................*......
        vmla.S32 q4, q5, r12             // ........................*.....
        vstrw.U32 q4, [r0, #-16]         // .........................*....

                                          // ------ cycle (expected) ------>
                                          // 0                        25
                                          // |------------------------|-----
        // vsub.U32 q2, q5, q6            // *..............................
        // vqrdmulh.S32 q7, q2, r6        // ....*..........................
        // ldrd r7, r10, [r11, #8]        // ...*...........................
        // vmul.S32 q2, q2, r4            // .*.............................
        // vsub.U32 q1, q3, q4            // .....*.........................
        // vmla.S32 q2, q7, r12           // ........*......................
        // vadd.U32 q0, q3, q4            // .......*.......................
        // vmul.S32 q3, q1, r7            // ..........*....................
        // vadd.U32 q7, q5, q6            // ..*............................
        // vqrdmulh.S32 q6, q1, r10       // ......*........................
        // vadd.U32 q5, q0, q7            // .............*.................
        // ldrd r8, r3, [r11], #24        // .........*.....................
        // vmla.S32 q3, q6, r12           // ..............*................
        // vstrw.U32 q5, [r0], #(64)      // ...............*...............
        // vadd.U32 q4, q3, q2            // ...................*...........
        // vstrw.U32 q4, [r0, #-48]       // .......................*.......
        // vsub.U32 q2, q3, q2            // .................*.............
        // vqrdmulh.S32 q1, q2, r3        // ..................*............
        // vmul.S32 q2, q2, r8            // ......................*........
        // vmla.S32 q2, q1, r12           // ........................*......
        // vsub.U32 q1, q0, q7            // ...........*...................
        // vqrdmulh.S32 q0, q1, r3        // ............*..................
        // vmul.S32 q7, q1, r8            // ................*..............
        // vstrw.U32 q2, [r0, #-16]       // .........................*.....
        // vmla.S32 q7, q0, r12           // ....................*..........
        // vstrw.U32 q7, [r0, #-32]       // .....................*.........


        sub in, in, #(4*256)

        // TEMPORARY: Barrett reduction
        barrett_const .req r1
        .equ const_barrett, 63
        movw barrett_const, #:lower16:const_barrett
        movt barrett_const, #:upper16:const_barrett
        mov lr, #64
1:
        vldrw.u32 data0, [in]
        vqrdmulh.s32 tmp, data0, barrett_const
        vmla.s32 data0, tmp, modulus
        vstrw.u32 data0, [in], #16
        le lr, 1b
2:
        sub in, in, #(4*256)
        .unreq barrett_const

        // Layers 3,4

        // 4 butterfly blocks per root config, 4 root configs
        // loop over root configs

        count .req r1
        mov count, #4

out_start:
        ldrd root0, root0_twisted, [root_ptr], #+8
        ldrd root1, root1_twisted, [root_ptr], #+8
        ldrd root2, root2_twisted, [root_ptr], #+8

        mov lr, #4
                                       // Instructions:    2
                                       // Expected cycles: 3
                                       // Expected IPC:    0.67
                                       //
                                       // Wall time:     0.00s
                                       // User time:     0.00s
                                       //
                                       // ----- cycle (expected) ------>
                                       // 0                        25
                                       // |------------------------|----
        vldrw.U32 q6, [r0, #64]        // *.............................
        vldrw.U32 q2, [r0]             // ..*...........................

                                        // ------ cycle (expected) ------>
                                        // 0                        25
                                        // |------------------------|-----
        // vldrw.U32 q2, [r0]           // ..*............................
        // vldrw.U32 q6, [r0, #64]      // *..............................

        sub lr, lr, #1
.p2align 2
layer34_loop:
                                         // Instructions:    28
                                         // Expected cycles: 28
                                         // Expected IPC:    1.00
                                         //
                                         // Wall time:     1.26s
                                         // User time:     1.26s
                                         //
                                         // ----- cycle (expected) ------>
                                         // 0                        25
                                         // |------------------------|----
        vsub.U32 q4, q2, q6              // *.............................
        vmul.S32 q7, q4, r4              // .*............................
        vldrw.U32 q1, [r0, #128]         // ..*...........................
        vqrdmulh.S32 q0, q4, r5          // ...*..........................
        vldrw.U32 q5, [r0, #192]         // ....*.........................
        vmla.S32 q7, q0, r12             // .....*........................
        vsub.U32 q4, q1, q5              // ......*.......................
        vmul.S32 q0, q4, r6              // .......*......................
        vadd.U32 q3, q2, q6              // ........*.....................
        vqrdmulh.S32 q6, q4, r7          // .........*....................
        vadd.U32 q5, q1, q5              // ..........*...................
        vmla.S32 q0, q6, r12             // ...........*..................
        vsub.U32 q1, q3, q5              // ............*.................
        vqrdmulh.S32 q4, q1, r3          // .............*................
        vldrw.U32 q2, [r0, #16]          // ..............e...............
        vmul.S32 q1, q1, r2              // ...............*..............
        vldrw.U32 q6, [r0, #80]          // ................e.............
        vmla.S32 q1, q4, r12             // .................*............
        vsub.U32 q4, q7, q0              // ..................*...........
        vstrw.U32 q1, [r0, #128]         // ...................*..........
        vadd.U32 q0, q7, q0              // ....................*.........
        vstrw.U32 q0, [r0, #64]          // .....................*........
        vmul.S32 q7, q4, r2              // ......................*.......
        vadd.U32 q5, q3, q5              // .......................*......
        vqrdmulh.S32 q0, q4, r3          // ........................*.....
        vstrw.U32 q5, [r0], #(16)        // .........................*....
        vmla.S32 q7, q0, r12             // ..........................*...
        vstrw.U32 q7, [r0, #176]         // ...........................*..

                                                   // ----------- cycle (expected) ------------>
                                                   // 0                        25
                                                   // |------------------------|----------------
        // vldrw.u32 q0, [r0]                      // e.............'.............~.............
        // vldrw.u32 q1, [r0, #(4*1*16)]           // ..e...........'...............~...........
        // vldrw.u32 q2, [r0, #(4*2*16)]           // ..............'.*.........................
        // vldrw.u32 q3, [r0, #(4*3*16)]           // ..............'...*.......................
        // vsub.u32       q4, q0,  q1              // ..............*...........................
        // vadd.u32       q0,  q0,  q1             // ..............'.......*...................
        // vmul.s32       q1,  q4, r4              // ..............'*..........................
        // vqrdmulh.s32   q4,  q4, r5              // ..............'..*........................
        // vmla.s32       q1,  q4, r12             // ..............'....*......................
        // vsub.u32       q4, q2,  q3              // ..............'.....*.....................
        // vadd.u32       q2,  q2,  q3             // ..............'.........*.................
        // vmul.s32       q3,  q4, r6              // ..............'......*....................
        // vqrdmulh.s32   q4,  q4, r7              // ..............'........*..................
        // vmla.s32       q3,  q4, r12             // ..............'..........*................
        // vsub.u32       q4, q0,  q2              // ..............'...........*...............
        // vadd.u32       q0,  q0,  q2             // .........~....'......................*....
        // vmul.s32       q2,  q4, r2              // .~............'..............*............
        // vqrdmulh.s32   q4,  q4, r3              // ..............'............*..............
        // vmla.s32       q2,  q4, r12             // ...~..........'................*..........
        // vsub.u32       q4, q1,  q3              // ....~.........'.................*.........
        // vadd.u32       q1,  q1,  q3             // ......~.......'...................*.......
        // vmul.s32       q3,  q4, r2              // ........~.....'.....................*.....
        // vqrdmulh.s32   q4,  q4, r3              // ..........~...'.......................*...
        // vmla.s32       q3,  q4, r12             // ............~.'.........................*.
        // vstrw.u32 q0, [r0], #(16)               // ...........~..'........................*..
        // vstrw.u32 q1, [r0, #(4*16*1 - 16)]      // .......~......'....................*......
        // vstrw.u32 q2, [r0, #(4*16*2 - 16)]      // .....~........'..................*........
        // vstrw.u32 q3, [r0, #(4*16*3 - 16)]      // .............~'..........................*

        le lr, layer34_loop
                                         // Instructions:    26
                                         // Expected cycles: 26
                                         // Expected IPC:    1.00
                                         //
                                         // Wall time:     0.13s
                                         // User time:     0.13s
                                         //
                                         // ----- cycle (expected) ------>
                                         // 0                        25
                                         // |------------------------|----
        vsub.U32 q3, q2, q6              // *.............................
        vmul.S32 q7, q3, r4              // .*............................
        vldrw.U32 q1, [r0, #192]         // ..*...........................
        vqrdmulh.S32 q3, q3, r5          // ...*..........................
        vldrw.U32 q4, [r0, #128]         // ....*.........................
        vmla.S32 q7, q3, r12             // .....*........................
        vsub.U32 q5, q4, q1              // ......*.......................
        vqrdmulh.S32 q3, q5, r7          // .......*......................
        vadd.U32 q1, q4, q1              // ........*.....................
        vmul.S32 q0, q5, r6              // .........*....................
        vadd.U32 q2, q2, q6              // ..........*...................
        vmla.S32 q0, q3, r12             // ...........*..................
        vsub.U32 q4, q2, q1              // ............*.................
        vmul.S32 q3, q4, r2              // .............*................
        vadd.U32 q6, q7, q0              // ..............*...............
        vqrdmulh.S32 q4, q4, r3          // ...............*..............
        vsub.U32 q7, q7, q0              // ................*.............
        vqrdmulh.S32 q5, q7, r3          // .................*............
        vstrw.U32 q6, [r0, #64]          // ..................*...........
        vmla.S32 q3, q4, r12             // ...................*..........
        vstrw.U32 q3, [r0, #128]         // ....................*.........
        vadd.U32 q6, q2, q1              // .....................*........
        vmul.S32 q7, q7, r2              // ......................*.......
        vstrw.U32 q6, [r0], #(16)        // .......................*......
        vmla.S32 q7, q5, r12             // ........................*.....
        vstrw.U32 q7, [r0, #176]         // .........................*....

                                          // ------ cycle (expected) ------>
                                          // 0                        25
                                          // |------------------------|-----
        // vsub.U32 q4, q2, q6            // *..............................
        // vmul.S32 q7, q4, r4            // .*.............................
        // vldrw.U32 q1, [r0, #128]       // ....*..........................
        // vqrdmulh.S32 q0, q4, r5        // ...*...........................
        // vldrw.U32 q5, [r0, #192]       // ..*............................
        // vmla.S32 q7, q0, r12           // .....*.........................
        // vsub.U32 q4, q1, q5            // ......*........................
        // vmul.S32 q0, q4, r6            // .........*.....................
        // vadd.U32 q3, q2, q6            // ..........*....................
        // vqrdmulh.S32 q6, q4, r7        // .......*.......................
        // vadd.U32 q5, q1, q5            // ........*......................
        // vmla.S32 q0, q6, r12           // ...........*...................
        // vsub.U32 q1, q3, q5            // ............*..................
        // vqrdmulh.S32 q4, q1, r3        // ...............*...............
        // vmul.S32 q1, q1, r2            // .............*.................
        // vmla.S32 q1, q4, r12           // ...................*...........
        // vsub.U32 q4, q7, q0            // ................*..............
        // vstrw.U32 q1, [r0, #128]       // ....................*..........
        // vadd.U32 q0, q7, q0            // ..............*................
        // vstrw.U32 q0, [r0, #64]        // ..................*............
        // vmul.S32 q7, q4, r2            // ......................*........
        // vadd.U32 q5, q3, q5            // .....................*.........
        // vqrdmulh.S32 q0, q4, r3        // .................*.............
        // vstrw.U32 q5, [r0], #(16)      // .......................*.......
        // vmla.S32 q7, q0, r12           // ........................*......
        // vstrw.U32 q7, [r0, #176]       // .........................*.....

        add in, in, #(4*64 - 4*16)

        subs count, count, #1
        bne out_start

        sub in, in, #(4*256)

        // TEMPORARY: Barrett reduction
        barrett_const .req r1
        movw barrett_const, #:lower16:const_barrett
        movt barrett_const, #:upper16:const_barrett
        mov lr, #64
1:
        vldrw.u32 data0, [in]
        vqrdmulh.s32 tmp, data0, barrett_const
        vmla.s32 data0, tmp, modulus
        vstrw.u32 data0, [in], #16
        le lr, 1b
2:
        sub in, in, #(4*256)
        .unreq barrett_const

        in_low       .req r0
        in_high      .req r1
        add in_high, in_low, #(4*128)

        // Layers 1,2

        ldrd root0, root0_twisted, [root_ptr], #+8
        ldrd root1, root1_twisted, [root_ptr], #+8
        ldrd root2, root2_twisted, [root_ptr], #+8

        mov lr, #16
                                        // Instructions:    2
                                        // Expected cycles: 3
                                        // Expected IPC:    0.67
                                        //
                                        // Wall time:     0.00s
                                        // User time:     0.00s
                                        //
                                        // ----- cycle (expected) ------>
                                        // 0                        25
                                        // |------------------------|----
        vldrw.U32 q4, [r1]              // *.............................
        vldrw.U32 q5, [r1, #256]        // ..*...........................

                                         // ------ cycle (expected) ------>
                                         // 0                        25
                                         // |------------------------|-----
        // vldrw.U32 q5, [r1, #256]      // ..*............................
        // vldrw.U32 q4, [r1]            // *..............................

        sub lr, lr, #1
.p2align 2
layer12_loop:
                                        // Instructions:    28
                                        // Expected cycles: 28
                                        // Expected IPC:    1.00
                                        //
                                        // Wall time:     1.24s
                                        // User time:     1.24s
                                        //
                                        // ----- cycle (expected) ------>
                                        // 0                        25
                                        // |------------------------|----
        vsub.U32 q6, q4, q5             // *.............................
        vmul.S32 q7, q6, r6             // .*............................
        vldrw.U32 q3, [r0]              // ..*...........................
        vqrdmulh.S32 q0, q6, r7         // ...*..........................
        vldrw.U32 q2, [r0, #256]        // ....*.........................
        vsub.U32 q1, q3, q2             // .....*........................
        vqrdmulh.S32 q6, q1, r5         // ......*.......................
        vadd.U32 q4, q4, q5             // .......*......................
        vmul.S32 q1, q1, r4             // ........*.....................
        vadd.U32 q2, q3, q2             // .........*....................
        vmla.S32 q7, q0, r12            // ..........*...................
        vsub.U32 q3, q2, q4             // ...........*..................
        vmla.S32 q1, q6, r12            // ............*.................
        vldrw.U32 q5, [r1, #272]        // .............e................
        vmul.S32 q0, q3, r2             // ..............*...............
        vadd.U32 q4, q2, q4             // ...............*..............
        vstrw.U32 q4, [r0], #16         // ................*.............
        vsub.U32 q2, q1, q7             // .................*............
        vqrdmulh.S32 q4, q3, r3         // ..................*...........
        vadd.U32 q6, q1, q7             // ...................*..........
        vmla.S32 q0, q4, r12            // ....................*.........
        vldrw.U32 q4, [r1, #16]         // .....................e........
        vmul.S32 q7, q2, r2             // ......................*.......
        vstrw.U32 q0, [r1], #16         // .......................*......
        vqrdmulh.S32 q1, q2, r3         // ........................*.....
        vstrw.U32 q6, [r0, #240]        // .........................*....
        vmla.S32 q7, q1, r12            // ..........................*...
        vstrw.U32 q7, [r1, #240]        // ...........................*..

                                                 // ------------ cycle (expected) ------------>
                                                 // 0                        25
                                                 // |------------------------|-----------------
        // vldrw.u32 q0, [r0]                    // ...............'.*.........................
        // vldrw.u32 q1, [r0,  #(4*64)]          // ...............'...*.......................
        // vldrw.u32 q2, [r1]                    // ........e......'....................~......
        // vldrw.u32 q3, [r1, #(4*64)]           // e..............'............~..............
        // vsub.u32       q4, q0,  q1            // ...............'....*......................
        // vadd.u32       q0,  q0,  q1           // ...............'........*..................
        // vmul.s32       q1,  q4, r4            // ...............'.......*...................
        // vqrdmulh.s32   q4,  q4, r5            // ...............'.....*.....................
        // vmla.s32       q1,  q4, r12           // ...............'...........*...............
        // vsub.u32       q4, q2,  q3            // ...............*...........................
        // vadd.u32       q2,  q2,  q3           // ...............'......*....................
        // vmul.s32       q3,  q4, r6            // ...............'*..........................
        // vqrdmulh.s32   q4,  q4, r7            // ...............'..*........................
        // vmla.s32       q3,  q4, r12           // ...............'.........*.................
        // vsub.u32       q4, q0,  q2            // ...............'..........*................
        // vadd.u32       q0,  q0,  q2           // ..~............'..............*............
        // vmul.s32       q2,  q4, r2            // .~.............'.............*.............
        // vqrdmulh.s32   q4,  q4, r3            // .....~.........'.................*.........
        // vmla.s32       q2,  q4, r12           // .......~.......'...................*.......
        // vsub.u32       q4, q1,  q3            // ....~..........'................*..........
        // vadd.u32       q1,  q1,  q3           // ......~........'..................*........
        // vmul.s32       q3,  q4, r2            // .........~.....'.....................*.....
        // vqrdmulh.s32   q4,  q4, r3            // ...........~...'.......................*...
        // vmla.s32       q3,  q4, r12           // .............~.'.........................*.
        // vstrw.u32 q0, [r0], #16               // ...~...........'...............*...........
        // vstrw.u32 q1, [r0, #(4*64 - 16)]      // ............~..'........................*..
        // vstrw.u32 q2, [r1], #16               // ..........~....'......................*....
        // vstrw.u32 q3, [r1, #(4*64 - 16)]      // ..............~'..........................*

        le lr, layer12_loop
                                        // Instructions:    26
                                        // Expected cycles: 26
                                        // Expected IPC:    1.00
                                        //
                                        // Wall time:     0.13s
                                        // User time:     0.13s
                                        //
                                        // ----- cycle (expected) ------>
                                        // 0                        25
                                        // |------------------------|----
        vsub.U32 q3, q4, q5             // *.............................
        vldrw.U32 q7, [r0, #256]        // .*............................
        vqrdmulh.S32 q2, q3, r7         // ..*...........................
        vldrw.U32 q6, [r0]              // ...*..........................
        vmul.S32 q0, q3, r6             // ....*.........................
        vsub.U32 q3, q6, q7             // .....*........................
        vmul.S32 q1, q3, r4             // ......*.......................
        vadd.U32 q6, q6, q7             // .......*......................
        vqrdmulh.S32 q3, q3, r5         // ........*.....................
        vadd.U32 q4, q4, q5             // .........*....................
        vmla.S32 q0, q2, r12            // ..........*...................
        vsub.U32 q2, q6, q4             // ...........*..................
        vmla.S32 q1, q3, r12            // ............*.................
        vadd.U32 q7, q6, q4             // .............*................
        vqrdmulh.S32 q6, q2, r3         // ..............*...............
        vadd.U32 q4, q1, q0             // ...............*..............
        vmul.S32 q5, q2, r2             // ................*.............
        vstrw.U32 q7, [r0], #16         // .................*............
        vmla.S32 q5, q6, r12            // ..................*...........
        vsub.U32 q6, q1, q0             // ...................*..........
        vmul.S32 q7, q6, r2             // ....................*.........
        vstrw.U32 q4, [r0, #240]        // .....................*........
        vqrdmulh.S32 q4, q6, r3         // ......................*.......
        vstrw.U32 q5, [r1], #16         // .......................*......
        vmla.S32 q7, q4, r12            // ........................*.....
        vstrw.U32 q7, [r1, #240]        // .........................*....

                                         // ------ cycle (expected) ------>
                                         // 0                        25
                                         // |------------------------|-----
        // vsub.U32 q6, q4, q5           // *..............................
        // vmul.S32 q7, q6, r6           // ....*..........................
        // vldrw.U32 q3, [r0]            // ...*...........................
        // vqrdmulh.S32 q0, q6, r7       // ..*............................
        // vldrw.U32 q2, [r0, #256]      // .*.............................
        // vsub.U32 q1, q3, q2           // .....*.........................
        // vqrdmulh.S32 q6, q1, r5       // ........*......................
        // vadd.U32 q4, q4, q5           // .........*.....................
        // vmul.S32 q1, q1, r4           // ......*........................
        // vadd.U32 q2, q3, q2           // .......*.......................
        // vmla.S32 q7, q0, r12          // ..........*....................
        // vsub.U32 q3, q2, q4           // ...........*...................
        // vmla.S32 q1, q6, r12          // ............*..................
        // vmul.S32 q0, q3, r2           // ................*..............
        // vadd.U32 q4, q2, q4           // .............*.................
        // vstrw.U32 q4, [r0], #16       // .................*.............
        // vsub.U32 q2, q1, q7           // ...................*...........
        // vqrdmulh.S32 q4, q3, r3       // ..............*................
        // vadd.U32 q6, q1, q7           // ...............*...............
        // vmla.S32 q0, q4, r12          // ..................*............
        // vmul.S32 q7, q2, r2           // ....................*..........
        // vstrw.U32 q0, [r1], #16       // .......................*.......
        // vqrdmulh.S32 q1, q2, r3       // ......................*........
        // vstrw.U32 q6, [r0, #240]      // .....................*.........
        // vmla.S32 q7, q1, r12          // ........................*......
        // vstrw.U32 q7, [r1, #240]      // .........................*.....


        // Restore MVE vector registers
        vpop {d8-d15}
        // Restore GPRs
        pop {r4-r11,lr}
        bx lr
