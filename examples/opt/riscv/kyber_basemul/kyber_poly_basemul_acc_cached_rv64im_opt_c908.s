.macro load_coeffs poly, len, wordLen
  lh s0,  \len*\wordLen*0(\poly)
  lh s1,  \len*\wordLen*1(\poly)
  lh s2,  \len*\wordLen*2(\poly)
  lh s3,  \len*\wordLen*3(\poly)
  lh s4,  \len*\wordLen*4(\poly)
  lh s5,  \len*\wordLen*5(\poly)
  lh s6,  \len*\wordLen*6(\poly)
  lh s7,  \len*\wordLen*7(\poly)
  lh s8,  \len*\wordLen*8(\poly)
  lh s9,  \len*\wordLen*9(\poly)
  lh s10, \len*\wordLen*10(\poly)
  lh s11, \len*\wordLen*11(\poly)
  lh a2,  \len*\wordLen*12(\poly)
  lh a3,  \len*\wordLen*13(\poly)
  lh a4,  \len*\wordLen*14(\poly)
  lh a5,  \len*\wordLen*15(\poly)
.endm

.macro store_coeffs poly, len, wordLen
  sh s0,  \len*\wordLen*0(\poly)
  sh s1,  \len*\wordLen*1(\poly)
  sh s2,  \len*\wordLen*2(\poly)
  sh s3,  \len*\wordLen*3(\poly)
  sh s4,  \len*\wordLen*4(\poly)
  sh s5,  \len*\wordLen*5(\poly)
  sh s6,  \len*\wordLen*6(\poly)
  sh s7,  \len*\wordLen*7(\poly)
  sh s8,  \len*\wordLen*8(\poly)
  sh s9,  \len*\wordLen*9(\poly)
  sh s10, \len*\wordLen*10(\poly)
  sh s11, \len*\wordLen*11(\poly)
  sh a2,  \len*\wordLen*12(\poly)
  sh a3,  \len*\wordLen*13(\poly)
  sh a4,  \len*\wordLen*14(\poly)
  sh a5,  \len*\wordLen*15(\poly)
.endm

.macro save_regs
  sd s0,  0*8(sp)
  sd s1,  1*8(sp)
  sd s2,  2*8(sp)
  sd s3,  3*8(sp)
  sd s4,  4*8(sp)
  sd s5,  5*8(sp)
  sd s6,  6*8(sp)
  sd s7,  7*8(sp)
  sd s8,  8*8(sp)
  sd s9,  9*8(sp)
  sd s10, 10*8(sp)
  sd s11, 11*8(sp)
  sd gp,  12*8(sp)
  sd tp,  13*8(sp)
  sd ra,  14*8(sp)
.endm

.macro restore_regs
  ld s0,  0*8(sp)
  ld s1,  1*8(sp)
  ld s2,  2*8(sp)
  ld s3,  3*8(sp)
  ld s4,  4*8(sp)
  ld s5,  5*8(sp)
  ld s6,  6*8(sp)
  ld s7,  7*8(sp)
  ld s8,  8*8(sp)
  ld s9,  9*8(sp)
  ld s10, 10*8(sp)
  ld s11, 11*8(sp)
  ld gp,  12*8(sp)
  ld tp,  13*8(sp)
  ld ra,  14*8(sp)
.endm

// a <- a*b*(-2^{-64}) mod+- q
// q32: q<<32; bqinv: b*qinv
.macro plant_mul_const_inplace q32, bqinv, a
  mul  \a, \a, \bqinv
  srai \a, \a, 32
  addi \a, \a, 8
  mulh \a, \a, \q32
.endm

// r <- a*b*(-2^{-64}) mod+- q
// q32: q<<32; bqinv: b*qinv
.macro plant_mul_const q32, bqinv, a, r
    mul  \r, \a, \bqinv
    srai \r, \r, 32
    addi \r, \r, 8
    mulh \r, \r, \q32
.endm

// each layer increases coefficients by 0.5q; In ct_butterfly, twiddle and tmp can be reused because each twiddle is only used once. The gs_butterfly cannot.
.macro ct_butterfly coeff0, coeff1, twiddle, q, tmp
  plant_mul_const \q, \twiddle, \coeff1, \tmp
  sub \coeff1, \coeff0, \tmp
  add \coeff0, \coeff0, \tmp
.endm

.macro gs_butterfly coeff0, coeff1, twiddle, q, tmp
  sub \tmp, \coeff0, \coeff1
  add \coeff0, \coeff0, \coeff1
  plant_mul_const \q, \twiddle, \tmp, \coeff1
.endm

// in-place plantard reduction to a
// output \in (-0.5q, 0.5q); q32: q<<32
.macro plant_red q32, qinv, a
  mul  \a, \a, \qinv
  srai \a, \a, 32
  addi \a, \a, 8
  mulh \a, \a, \q32
.endm

.equ q,    3329
.equ q32,  0xd0100000000                // q << 32
.equ qinv, 0x3c0f12886ba8f301           // q^-1 mod 2^64
.equ plantconst, 0x13afb7680bb055       // (((-2**64) % q) * qinv) % (2**64)
.equ plantconst2, 0x1a390f4d9791e139    // (((-2**64) % q) * ((-2**64) % q) * qinv) % (2**64)

// void poly_basemul_acc_cached_rv64im(int32_t *r, const int16_t *a, const int16_t *b, int16_t *b_cache)
// compute basemul using cached b_cache and accumulate the 32-bit results into r
// a0: r, a1: a, a2: b, a3: b_cache
// a5: q<<32, a6: loop control
// t0-t3: a[2i,2i+1],b[2i,2i+1]
// t4: accumulated value, t5-t6: temp
.global poly_basemul_acc_cached_rv64im_opt_c908
.align 2
poly_basemul_acc_cached_rv64im_opt_c908:
    li a5, q32
    li a6, 64
                                // Instructions:    3
                                // Expected cycles: 3
                                // Expected IPC:    1.00
                                //
                                // Cycle bound:     3.0
                                // IPC bound:       1.00
                                //
                                // Wall time:     0.02s
                                // User time:     0.02s
                                //
                                // ----- cycle (expected) ------>
                                // 0                        25
                                // |------------------------|----
        lh x16, 2*1(x11)        // *.............................
        lh x4, 2*0(x13)         // .*............................
        lh x19, 2*0(x12)        // ..*...........................

                                 // ------ cycle (expected) ------>
                                 // 0                        25
                                 // |------------------------|-----
        // lh x16, 2*1(x11)      // *..............................
        // lh x4, 2*0(x13)       // .*.............................
        // lh x19, 2*0(x12)      // ..*............................

        addi a6, a6, -1
poly_basemul_acc_cached_rv64im_loop:
                                  // Instructions:    38
                                  // Expected cycles: 19
                                  // Expected IPC:    2.00
                                  //
                                  // Cycle bound:     22.0
                                  // IPC bound:       1.73
                                  //
                                  // Wall time:     16.32s
                                  // User time:     16.32s
                                  //
                                  // ----- cycle (expected) ------>
                                  // 0                        25
                                  // |------------------------|----
        lh x15, 2*0(x11)          // *.............................
        mul x27, x16, x19         // *.............................
        lh x24, 2*1(x12)          // .*............................
        mul x6, x16, x4           // .*............................
        lh x7, 2*1(x13)           // ..*...........................
        addi x13, x13, 2*2        // ..*...........................
        lh x1, 2*3(x12)           // ...*..........................
        mul x5, x15, x19          // ...*..........................
        lh x20, 2*2(x12)          // ....*.........................
        addi x12, x12, 2*4        // ....*.........................
        lh x23, 2*2(x11)          // .....*........................
        mul x29, x15, x24         // .....*........................
        lh x22, 2*3(x11)          // ......*.......................
        addi x11, x11, 2*4        // ......*.......................
        lh x16, 2*1(x11)          // .......e......................
        add x5, x6, x5            // .......*......................
        lh x4, 2*0(x13)           // ........e.....................
        mul x26, x23, x20         // ........*.....................
        lh x19, 2*0(x12)          // .........e....................
        mul x14, x23, x1          // .........*....................
        lw x23, 4*0(x10)          // ..........*...................
        mul x8, x22, x7           // ..........*...................
        lw x30, 4*1(x10)          // ...........*..................
        add x27, x29, x27         // ...........*..................
        lw x25, 4*3(x10)          // ............*.................
        mul x17, x22, x20         // ............*.................
        lw x7, 4*2(x10)           // .............*................
        add x18, x27, x30         // .............*................
        sw x18, 4*1(x10)          // ..............*...............
        add x23, x5, x23          // ..............*...............
        sw x23, 4*0(x10)          // ...............*..............
        add x28, x8, x26          // ...............*..............
        add x17, x14, x17         // ................*.............
        add x28, x28, x7          // ................*.............
        add x27, x17, x25         // .................*............
        sw x28, 4*2(x10)          // .................*............
        sw x27, 4*3(x10)          // ..................*...........
        addi x10, x10, 4*4        // ..................*...........

                                    // ------ cycle (expected) ------>
                                    // 0                        25
                                    // |------------------------|-----
        // lh x5, 2*0(x11)          // ............*..................
        // lh x6, 2*1(x11)          // e...........'......~...........
        // lh x30, 2*0(x13)         // .e..........'.......~..........
        // lh x7, 2*0(x12)          // ..e.........'........~.........
        // lh x28, 2*1(x12)         // ............'*.................
        // lw x29, 4*0(x10)         // ...~........'.........*........
        // mul x30, x6, x30         // ............'*.................
        // mul x31, x5, x7          // ............'..*...............
        // add x30, x30, x31        // ~...........'......*...........
        // add x30, x30, x29        // .......~....'.............*....
        // sw  x30, 4*0(x10)        // ........~...'..............*...
        // lw  x29, 4*1(x10)        // ....~.......'..........*.......
        // mul x30, x5, x28         // ............'....*.............
        // mul x31, x6, x7          // ............*..................
        // add x30, x30, x31        // ....~.......'..........*.......
        // add x30, x30, x29        // ......~.....'............*.....
        // sw  x30, 4*1(x10)        // .......~....'.............*....
        // lh x5, 2*2(x11)          // ............'....*.............
        // lh x6, 2*3(x11)          // ............'.....*............
        // lh x30, 2*1(x13)         // ............'.*................
        // lh x7, 2*2(x12)          // ............'...*..............
        // lh x28, 2*3(x12)         // ............'..*...............
        // lw x29, 4*2(x10)         // ......~.....'............*.....
        // mul x30, x6, x30         // ...~........'.........*........
        // mul x31, x5, x7          // .~..........'.......*..........
        // add x30, x30, x31        // ........~...'..............*...
        // add x30, x30, x29        // .........~..'...............*..
        // sw  x30, 4*2(x10)        // ..........~.'................*.
        // lw  x29, 4*3(x10)        // .....~......'...........*......
        // mul x30, x5, x28         // ..~.........'........*.........
        // mul x31, x6, x7          // .....~......'...........*......
        // add x30, x30, x31        // .........~..'...............*..
        // add x30, x30, x29        // ..........~.'................*.
        // sw  x30, 4*3(x10)        // ...........~'.................*
        // addi x10, x10, 4*4       // ...........~'.................*
        // addi x11, x11, 2*4       // ............'.....*............
        // addi x12, x12, 2*4       // ............'...*..............
        // addi x13, x13, 2*2       // ............'.*................

        addi a6, a6, -1
        bne a6, zero, poly_basemul_acc_cached_rv64im_loop
                                  // Instructions:    35
                                  // Expected cycles: 18
                                  // Expected IPC:    1.94
                                  //
                                  // Cycle bound:     18.0
                                  // IPC bound:       1.94
                                  //
                                  // Wall time:     0.54s
                                  // User time:     0.54s
                                  //
                                  // ----- cycle (expected) ------>
                                  // 0                        25
                                  // |------------------------|----
        lh x22, 2*2(x12)          // *.............................
        mul x5, x16, x19          // *.............................
        lh x27, 2*3(x11)          // .*............................
        lh x8, 2*0(x11)           // ..*...........................
        mul x14, x16, x4          // ..*...........................
        lh x28, 2*2(x11)          // ...*..........................
        addi x11, x11, 2*4        // ...*..........................
        lw x21, 4*0(x10)          // ....*.........................
        mul x17, x27, x22         // ....*.........................
        mul x4, x8, x19           // .....*........................
        lh x16, 2*3(x12)          // .....*........................
        mul x15, x28, x22         // ......*.......................
        lh x9, 2*1(x12)           // ......*.......................
        lh x6, 2*1(x13)           // .......*......................
        addi x13, x13, 2*2        // .......*......................
        lw x23, 4*1(x10)          // ........*.....................
        mul x26, x28, x16         // ........*.....................
        addi x12, x12, 2*4        // .........*....................
        mul x29, x8, x9           // .........*....................
        mul x18, x27, x6          // ..........*...................
        add x8, x14, x4           // ..........*...................
        add x30, x8, x21          // ...........*..................
        lw x7, 4*3(x10)           // ...........*..................
        add x14, x26, x17         // ............*.................
        sw x30, 4*0(x10)          // ............*.................
        lw x17, 4*2(x10)          // .............*................
        add x6, x29, x5           // .............*................
        add x1, x18, x15          // ..............*...............
        add x25, x6, x23          // ..............*...............
        sw x25, 4*1(x10)          // ...............*..............
        add x25, x1, x17          // ...............*..............
        sw x25, 4*2(x10)          // ................*.............
        add x24, x14, x7          // ................*.............
        sw x24, 4*3(x10)          // .................*............
        addi x10, x10, 4*4        // .................*............

                                   // ------ cycle (expected) ------>
                                   // 0                        25
                                   // |------------------------|-----
        // lh x15, 2*0(x11)        // ..*............................
        // mul x27, x16, x19       // *..............................
        // lh x24, 2*1(x12)        // ......*........................
        // mul x6, x16, x4         // ..*............................
        // lh x7, 2*1(x13)         // .......*.......................
        // addi x13, x13, 2*2      // .......*.......................
        // lh x1, 2*3(x12)         // .....*.........................
        // mul x5, x15, x19        // .....*.........................
        // lh x20, 2*2(x12)        // *..............................
        // addi x12, x12, 2*4      // .........*.....................
        // lh x23, 2*2(x11)        // ...*...........................
        // mul x29, x15, x24       // .........*.....................
        // lh x22, 2*3(x11)        // .*.............................
        // addi x11, x11, 2*4      // ...*...........................
        // add x5, x6, x5          // ..........*....................
        // mul x26, x23, x20       // ......*........................
        // mul x14, x23, x1        // ........*......................
        // lw x23, 4*0(x10)        // ....*..........................
        // mul x8, x22, x7         // ..........*....................
        // lw x30, 4*1(x10)        // ........*......................
        // add x27, x29, x27       // .............*.................
        // lw x25, 4*3(x10)        // ...........*...................
        // mul x17, x22, x20       // ....*..........................
        // lw x7, 4*2(x10)         // .............*.................
        // add x18, x27, x30       // ..............*................
        // sw x18, 4*1(x10)        // ...............*...............
        // add x23, x5, x23        // ...........*...................
        // sw x23, 4*0(x10)        // ............*..................
        // add x28, x8, x26        // ..............*................
        // add x17, x14, x17       // ............*..................
        // add x28, x28, x7        // ...............*...............
        // add x27, x17, x25       // ................*..............
        // sw x28, 4*2(x10)        // ................*..............
        // sw x27, 4*3(x10)        // .................*.............
        // addi x10, x10, 4*4      // .................*.............

ret