// Plantard based NTT implementation with l=16

.macro load_coeffs poly, len, wordLen
  lh s0,  \len*\wordLen*0(\poly)
  lh s1,  \len*\wordLen*1(\poly)
  lh s2,  \len*\wordLen*2(\poly)
  lh s3,  \len*\wordLen*3(\poly)
  lh s4,  \len*\wordLen*4(\poly)
  lh s5,  \len*\wordLen*5(\poly)
  lh s6,  \len*\wordLen*6(\poly)
  lh s7,  \len*\wordLen*7(\poly)
  lh s8,  \len*\wordLen*8(\poly)
  lh s9,  \len*\wordLen*9(\poly)
  lh s10, \len*\wordLen*10(\poly)
  lh s11, \len*\wordLen*11(\poly)
  lh a2,  \len*\wordLen*12(\poly)
  lh a3,  \len*\wordLen*13(\poly)
  lh a4,  \len*\wordLen*14(\poly)
  lh a5,  \len*\wordLen*15(\poly)
.endm

.macro store_coeffs poly, len, wordLen
  sh s0,  \len*\wordLen*0(\poly)
  sh s1,  \len*\wordLen*1(\poly)
  sh s2,  \len*\wordLen*2(\poly)
  sh s3,  \len*\wordLen*3(\poly)
  sh s4,  \len*\wordLen*4(\poly)
  sh s5,  \len*\wordLen*5(\poly)
  sh s6,  \len*\wordLen*6(\poly)
  sh s7,  \len*\wordLen*7(\poly)
  sh s8,  \len*\wordLen*8(\poly)
  sh s9,  \len*\wordLen*9(\poly)
  sh s10, \len*\wordLen*10(\poly)
  sh s11, \len*\wordLen*11(\poly)
  sh a2,  \len*\wordLen*12(\poly)
  sh a3,  \len*\wordLen*13(\poly)
  sh a4,  \len*\wordLen*14(\poly)
  sh a5,  \len*\wordLen*15(\poly)
.endm

.macro save_regs
  sd s0,  0*8(sp)
  sd s1,  1*8(sp)
  sd s2,  2*8(sp)
  sd s3,  3*8(sp)
  sd s4,  4*8(sp)
  sd s5,  5*8(sp)
  sd s6,  6*8(sp)
  sd s7,  7*8(sp)
  sd s8,  8*8(sp)
  sd s9,  9*8(sp)
  sd s10, 10*8(sp)
  sd s11, 11*8(sp)
  sd gp,  12*8(sp)
  sd tp,  13*8(sp)
  sd ra,  14*8(sp)
.endm

.macro restore_regs
  ld s0,  0*8(sp)
  ld s1,  1*8(sp)
  ld s2,  2*8(sp)
  ld s3,  3*8(sp)
  ld s4,  4*8(sp)
  ld s5,  5*8(sp)
  ld s6,  6*8(sp)
  ld s7,  7*8(sp)
  ld s8,  8*8(sp)
  ld s9,  9*8(sp)
  ld s10, 10*8(sp)
  ld s11, 11*8(sp)
  ld gp,  12*8(sp)
  ld tp,  13*8(sp)
  ld ra,  14*8(sp)
.endm

// a <- a*b*(-2^{-32}) mod+- q
// q48: q<<48; bqinv: b*qinv
.macro plant_mul_const_inplace q48, zeta, a
  mulw \a, \a, \zeta
  srai \a, \a, 16
  addi \a, \a, 8
  mulh \a, \a, \q48
.endm

.macro plant_mul_const_inplace_x2 q48, zeta, a_0, a_1
  mulw \a_0, \a_0, \zeta
  mulw \a_1, \a_1, \zeta
  srai \a_0, \a_0, 16
  srai \a_1, \a_1, 16
  addi \a_0, \a_0, 8
  addi \a_1, \a_1, 8
  mulh \a_0, \a_0, \q48
  mulh \a_1, \a_1, \q48
.endm

.macro plant_mul_const_inplace_x4 q48,   zeta_0, zeta_1, zeta_2, zeta_3,    a_0, a_1, a_2, a_3
  mulw \a_0, \a_0, \zeta_0
  mulw \a_1, \a_1, \zeta_1
  mulw \a_2, \a_2, \zeta_2
  mulw \a_3, \a_3, \zeta_3
  srai \a_0, \a_0, 16
  srai \a_1, \a_1, 16
  srai \a_2, \a_2, 16
  srai \a_3, \a_3, 16
  addi \a_0, \a_0, 8
  addi \a_1, \a_1, 8
  addi \a_2, \a_2, 8
  addi \a_3, \a_3, 8
  mulh \a_0, \a_0, \q48
  mulh \a_1, \a_1, \q48
  mulh \a_2, \a_2, \q48
  mulh \a_3, \a_3, \q48
.endm

// r <- a*b*(-2^{-32}) mod+- q
// q48: q<<48; zeta: b*qinv
.macro plant_mul_const q48, zeta, a, r
  mulw \r, \a, \zeta
  srai \r, \r, 16
  addi \r, \r, 8
  mulh \r, \r, \q48
.endm

.macro plant_mul_const_x2 q48, zeta_0, zeta_1, a_0, a_1, r_0, r_1
  mulw \r_0, \a_0, \zeta_0
  mulw \r_1, \a_1, \zeta_1
  srai \r_0, \r_0, 16
  srai \r_1, \r_1, 16
  addi \r_0, \r_0, 8
  addi \r_1, \r_1, 8
  mulh \r_0, \r_0, \q48
  mulh \r_1, \r_1, \q48
.endm

.macro plant_mul_const_x4    q48, zeta_0, zeta_1, zeta_2, zeta_3,      a_0, a_1, a_2, a_3,  r_0, r_1, r_2, r_3
  mulw \r_0, \a_0, \zeta_0
  mulw \r_1, \a_1, \zeta_1
  mulw \r_2, \a_2, \zeta_2
  mulw \r_3, \a_3, \zeta_3
  srai \r_0, \r_0, 16
  srai \r_1, \r_1, 16
  srai \r_2, \r_2, 16
  srai \r_3, \r_3, 16
  addi \r_0, \r_0, 8
  addi \r_1, \r_1, 8
  addi \r_2, \r_2, 8
  addi \r_3, \r_3, 8
  mulh \r_0, \r_0, \q48
  mulh \r_1, \r_1, \q48
  mulh \r_2, \r_2, \q48
  mulh \r_3, \r_3, \q48
.endm

// each layer increases coefficients by 0.5q; In ct_bfu, zeta and tmp can be reused because each zeta is only used once. The gs_bfu cannot.
// .macro ct_bfu a_0, a_1, zeta, q48, tmp
// plant_mul_const \q48, \zeta, \a_1, \tmp
// sub \a_1, \a_0, \tmp
// add \a_0, \a_0, \tmp
// .endm
.macro ct_bfu a_0, a_1, zeta, q48, tmp
  mulw \tmp, \a_1, \zeta
  srai \tmp, \tmp, 16
  addi \tmp, \tmp, 8
  mulh \tmp, \tmp, \q48
  sub \a_1, \a_0, \tmp
  add \a_0, \a_0, \tmp
.endm

.macro ct_bfu_x2  a_0_0, a_0_1, a_1_0, a_1_1,  zeta_0, zeta_1,  q48,  t_0, t_1
  mulw  \t_0, \a_0_1, \zeta_0
  mulw  \t_1, \a_1_1, \zeta_1
  srai \t_0, \t_0, 16
  srai \t_1, \t_1, 16
  addi \t_0, \t_0, 8
  addi \t_1, \t_1, 8
  mulh \t_0, \t_0, \q48
  mulh \t_1, \t_1, \q48
  sub  \a_0_1, \a_0_0, \t_0
  sub  \a_1_1, \a_1_0, \t_1
  add  \a_0_0, \a_0_0, \t_0
  add  \a_1_0, \a_1_0, \t_1
.endm

.macro ct_bfu_x8  a_0_0, a_0_1, a_1_0, a_1_1,  a_2_0, a_2_1, a_3_0, a_3_1,  a_4_0, a_4_1, a_5_0, a_5_1,  a_6_0, a_6_1, a_7_0, a_7_1,  zeta_0, zeta_1,  zeta_2, zeta_3,  zeta_4, zeta_5,  zeta_6, zeta_7,  q48,  t_0, t_1, t_2, t_3
  mulw \t_0, \a_0_1, \zeta_0
  mulw \t_1, \a_1_1, \zeta_1
  mulw \t_2, \a_2_1, \zeta_2
  mulw \t_3, \a_3_1, \zeta_3
  srai \t_0, \t_0, 16
  srai \t_1, \t_1, 16
  addi \t_0, \t_0, 8
  addi \t_1, \t_1, 8
  mulh \t_0, \t_0, \q48
  mulh \t_1, \t_1, \q48
  srai \t_2, \t_2, 16
  srai \t_3, \t_3, 16
  addi \t_2, \t_2, 8
  addi \t_3, \t_3, 8
  mulh \t_2, \t_2, \q48
  mulh \t_3, \t_3, \q48
  sub  \a_0_1, \a_0_0, \t_0
  sub  \a_1_1, \a_1_0, \t_1
  add  \a_0_0, \a_0_0, \t_0
  add  \a_1_0, \a_1_0, \t_1
  mulw \t_0, \a_4_1, \zeta_4
  mulw \t_1, \a_5_1, \zeta_5
  sub  \a_2_1, \a_2_0, \t_2
  sub  \a_3_1, \a_3_0, \t_3
  add  \a_2_0, \a_2_0, \t_2
  add  \a_3_0, \a_3_0, \t_3
  mulw \t_2, \a_6_1, \zeta_6
  mulw \t_3, \a_7_1, \zeta_7
  srai \t_0, \t_0, 16
  srai \t_1, \t_1, 16
  addi \t_0, \t_0, 8
  addi \t_1, \t_1, 8
  mulh \t_0, \t_0, \q48
  mulh \t_1, \t_1, \q48
  srai \t_2, \t_2, 16
  srai \t_3, \t_3, 16
  addi \t_2, \t_2, 8
  addi \t_3, \t_3, 8
  mulh \t_2, \t_2, \q48
  mulh \t_3, \t_3, \q48
  sub  \a_4_1, \a_4_0, \t_0
  sub  \a_5_1, \a_5_0, \t_1
  add  \a_4_0, \a_4_0, \t_0
  add  \a_5_0, \a_5_0, \t_1
  sub  \a_6_1, \a_6_0, \t_2
  sub  \a_7_1, \a_7_0, \t_3
  add  \a_6_0, \a_6_0, \t_2
  add  \a_7_0, \a_7_0, \t_3
.endm

.macro ct_bfu_x8_loadzetas  a_0_0, a_0_1, a_1_0, a_1_1,  a_2_0, a_2_1, a_3_0, a_3_1,  a_4_0, a_4_1, a_5_0, a_5_1,  a_6_0, a_6_1, a_7_0, a_7_1,  zeta_0, zeta_1,  zeta_2, zeta_3,  zeta_4, zeta_5,  zeta_6, zeta_7,  q48,  t_0, t_1, t_2, t_3
  lw   \t_0, \zeta_0(a1)
  lw   \t_1, \zeta_1(a1)
  lw   \t_2, \zeta_2(a1)
  lw   \t_3, \zeta_3(a1)
  mulw \t_0, \a_0_1, \t_0
  mulw \t_1, \a_1_1, \t_1
  mulw \t_2, \a_2_1, \t_2
  mulw \t_3, \a_3_1, \t_3
  srai \t_0, \t_0, 16
  srai \t_1, \t_1, 16
  addi \t_0, \t_0, 8
  addi \t_1, \t_1, 8
  mulh \t_0, \t_0, \q48
  mulh \t_1, \t_1, \q48
  srai \t_2, \t_2, 16
  srai \t_3, \t_3, 16
  addi \t_2, \t_2, 8
  addi \t_3, \t_3, 8
  mulh \t_2, \t_2, \q48
  mulh \t_3, \t_3, \q48
  sub  \a_0_1, \a_0_0, \t_0
  sub  \a_1_1, \a_1_0, \t_1
  add  \a_0_0, \a_0_0, \t_0
  lw   \t_0, \zeta_4(a1)
  add  \a_1_0, \a_1_0, \t_1
  lw   \t_1, \zeta_5(a1)
  mulw \t_0, \a_4_1, \t_0
  mulw \t_1, \a_5_1, \t_1
  sub  \a_2_1, \a_2_0, \t_2
  sub  \a_3_1, \a_3_0, \t_3
  add  \a_2_0, \a_2_0, \t_2
  lw   \t_2, \zeta_6(a1)
  add  \a_3_0, \a_3_0, \t_3
  lw   \t_3, \zeta_7(a1)
  mulw \t_2, \a_6_1, \t_2
  mulw \t_3, \a_7_1, \t_3
  srai \t_0, \t_0, 16
  srai \t_1, \t_1, 16
  addi \t_0, \t_0, 8
  addi \t_1, \t_1, 8
  mulh \t_0, \t_0, \q48
  mulh \t_1, \t_1, \q48
  srai \t_2, \t_2, 16
  srai \t_3, \t_3, 16
  addi \t_2, \t_2, 8
  addi \t_3, \t_3, 8
  mulh \t_2, \t_2, \q48
  mulh \t_3, \t_3, \q48
  sub  \a_4_1, \a_4_0, \t_0
  sub  \a_5_1, \a_5_0, \t_1
  add  \a_4_0, \a_4_0, \t_0
  add  \a_5_0, \a_5_0, \t_1
  sub  \a_6_1, \a_6_0, \t_2
  sub  \a_7_1, \a_7_0, \t_3
  add  \a_6_0, \a_6_0, \t_2
  add  \a_7_0, \a_7_0, \t_3
.endm

.macro gs_bfu a_0, a_1, zeta, q48, tmp
  sub \tmp, \a_0, \a_1
  add \a_0, \a_0, \a_1
  mulw \a_1, \tmp, \zeta
  srai \a_1, \a_1, 16
  addi \a_1, \a_1, 8
  mulh \a_1, \a_1, \q48
.endm

.macro gs_bfu_x2 a_0_0, a_0_1, a_1_0, a_1_1,  zeta_0, zeta_1, q48, t_0, t_1
  sub \t_0, \a_0_0, \a_0_1
  sub \t_1, \a_1_0, \a_1_1
  add \a_0_0, \a_0_0, \a_0_1
  add \a_1_0, \a_1_0, \a_1_1
  mulw \a_0_1, \t_0, \zeta_0
  mulw \a_1_1, \t_1, \zeta_1
  srai \a_0_1, \a_0_1, 16
  srai \a_1_1, \a_1_1, 16
  addi \a_0_1, \a_0_1, 8
  addi \a_1_1, \a_1_1, 8
  mulh \a_0_1, \a_0_1, \q48
  mulh \a_1_1, \a_1_1, \q48
.endm

.macro gs_bfu_x8  a_0_0, a_0_1, a_1_0, a_1_1,  a_2_0, a_2_1, a_3_0, a_3_1,  a_4_0, a_4_1, a_5_0, a_5_1,  a_6_0, a_6_1, a_7_0, a_7_1,  zeta_0, zeta_1,  zeta_2, zeta_3,  zeta_4, zeta_5,  zeta_6, zeta_7,  q48, t_0, t_1, t_2, t_3
  sub \t_0, \a_0_0, \a_0_1
  sub \t_1, \a_1_0, \a_1_1
  add \a_0_0, \a_0_0, \a_0_1
  add \a_1_0, \a_1_0, \a_1_1
  mulw \a_0_1, \t_0, \zeta_0
  mulw \a_1_1, \t_1, \zeta_1
  sub \t_2, \a_2_0, \a_2_1
  sub \t_3, \a_3_0, \a_3_1
  add \a_2_0, \a_2_0, \a_2_1
  add \a_3_0, \a_3_0, \a_3_1
  mulw \a_2_1, \t_2, \zeta_2
  mulw \a_3_1, \t_3, \zeta_3
  srai \a_0_1, \a_0_1, 16
  srai \a_1_1, \a_1_1, 16
  addi \a_0_1, \a_0_1, 8
  addi \a_1_1, \a_1_1, 8
  mulh \a_0_1, \a_0_1, \q48
  mulh \a_1_1, \a_1_1, \q48
  srai \a_2_1, \a_2_1, 16
  srai \a_3_1, \a_3_1, 16
  addi \a_2_1, \a_2_1, 8
  addi \a_3_1, \a_3_1, 8
  mulh \a_2_1, \a_2_1, \q48
  mulh \a_3_1, \a_3_1, \q48
  sub \t_0, \a_4_0, \a_4_1
  sub \t_1, \a_5_0, \a_5_1
  add \a_4_0, \a_4_0, \a_4_1
  add \a_5_0, \a_5_0, \a_5_1
  mulw \a_4_1, \t_0, \zeta_4
  mulw \a_5_1, \t_1, \zeta_5
  sub \t_2, \a_6_0, \a_6_1
  sub \t_3, \a_7_0, \a_7_1
  add \a_6_0, \a_6_0, \a_6_1
  add \a_7_0, \a_7_0, \a_7_1
  mulw \a_6_1, \t_2, \zeta_6
  mulw \a_7_1, \t_3, \zeta_7
  srai \a_4_1, \a_4_1, 16
  srai \a_5_1, \a_5_1, 16
  addi \a_4_1, \a_4_1, 8
  addi \a_5_1, \a_5_1, 8
  mulh \a_4_1, \a_4_1, \q48
  mulh \a_5_1, \a_5_1, \q48
  srai \a_6_1, \a_6_1, 16
  srai \a_7_1, \a_7_1, 16
  addi \a_6_1, \a_6_1, 8
  addi \a_7_1, \a_7_1, 8
  mulh \a_6_1, \a_6_1, \q48
  mulh \a_7_1, \a_7_1, \q48
.endm

.macro gs_bfu_x8_load_4zetas  a_0_0, a_0_1, a_1_0, a_1_1,  a_2_0, a_2_1, a_3_0, a_3_1,  a_4_0, a_4_1, a_5_0, a_5_1,  a_6_0, a_6_1, a_7_0, a_7_1,  zeta_0, zeta_1,  zeta_2, zeta_3,  q48, t_0, t_1, t_2, t_3
  lw  \t_2, \zeta_0(a1)
  sub \t_0, \a_0_0, \a_0_1
  sub \t_1, \a_1_0, \a_1_1
  add \a_0_0, \a_0_0, \a_0_1
  add \a_1_0, \a_1_0, \a_1_1
  mulw \a_0_1, \t_0, \t_2
  mulw \a_1_1, \t_1, \t_2
  sub \t_0, \a_2_0, \a_2_1
  sub \t_3, \a_3_0, \a_3_1
  lw  \t_2, \zeta_1(a1)
  add \a_2_0, \a_2_0, \a_2_1
  add \a_3_0, \a_3_0, \a_3_1
  mulw \a_2_1, \t_0, \t_2
  mulw \a_3_1, \t_3, \t_2
  srai \a_0_1, \a_0_1, 16
  srai \a_1_1, \a_1_1, 16
  addi \a_0_1, \a_0_1, 8
  addi \a_1_1, \a_1_1, 8
  mulh \a_0_1, \a_0_1, \q48
  mulh \a_1_1, \a_1_1, \q48
  srai \a_2_1, \a_2_1, 16
  srai \a_3_1, \a_3_1, 16
  addi \a_2_1, \a_2_1, 8
  addi \a_3_1, \a_3_1, 8
  mulh \a_2_1, \a_2_1, \q48
  mulh \a_3_1, \a_3_1, \q48
  sub \t_0, \a_4_0, \a_4_1
  sub \t_1, \a_5_0, \a_5_1
  lw  \t_2, \zeta_2(a1)
  add \a_4_0, \a_4_0, \a_4_1
  add \a_5_0, \a_5_0, \a_5_1
  mulw \a_4_1, \t_0, \t_2
  mulw \a_5_1, \t_1, \t_2
  sub \t_0, \a_6_0, \a_6_1
  sub \t_3, \a_7_0, \a_7_1
  lw  \t_2, \zeta_3(a1)
  add \a_6_0, \a_6_0, \a_6_1
  add \a_7_0, \a_7_0, \a_7_1
  mulw \a_6_1, \t_0, \t_2
  mulw \a_7_1, \t_3, \t_2
  srai \a_4_1, \a_4_1, 16
  srai \a_5_1, \a_5_1, 16
  addi \a_4_1, \a_4_1, 8
  addi \a_5_1, \a_5_1, 8
  mulh \a_4_1, \a_4_1, \q48
  mulh \a_5_1, \a_5_1, \q48
  srai \a_6_1, \a_6_1, 16
  srai \a_7_1, \a_7_1, 16
  addi \a_6_1, \a_6_1, 8
  addi \a_7_1, \a_7_1, 8
  mulh \a_6_1, \a_6_1, \q48
  mulh \a_7_1, \a_7_1, \q48
.endm

.macro gs_bfu_x8_load_2zetas  a_0_0, a_0_1, a_1_0, a_1_1,  a_2_0, a_2_1, a_3_0, a_3_1,  a_4_0, a_4_1, a_5_0, a_5_1,  a_6_0, a_6_1, a_7_0, a_7_1,  zeta_0, zeta_1,  q48, t_0, t_1, t_2, t_3
  lw  \t_2, \zeta_0(a1)
  sub \t_0, \a_0_0, \a_0_1
  sub \t_1, \a_1_0, \a_1_1
  add \a_0_0, \a_0_0, \a_0_1
  add \a_1_0, \a_1_0, \a_1_1
  mulw \a_0_1, \t_0, \t_2
  mulw \a_1_1, \t_1, \t_2
  sub \t_0, \a_2_0, \a_2_1
  sub \t_3, \a_3_0, \a_3_1
  add \a_2_0, \a_2_0, \a_2_1
  add \a_3_0, \a_3_0, \a_3_1
  mulw \a_2_1, \t_0, \t_2
  mulw \a_3_1, \t_3, \t_2
  srai \a_0_1, \a_0_1, 16
  srai \a_1_1, \a_1_1, 16
  addi \a_0_1, \a_0_1, 8
  addi \a_1_1, \a_1_1, 8
  mulh \a_0_1, \a_0_1, \q48
  mulh \a_1_1, \a_1_1, \q48
  srai \a_2_1, \a_2_1, 16
  srai \a_3_1, \a_3_1, 16
  addi \a_2_1, \a_2_1, 8
  addi \a_3_1, \a_3_1, 8
  mulh \a_2_1, \a_2_1, \q48
  mulh \a_3_1, \a_3_1, \q48
  lw  \t_2, \zeta_1(a1)
  sub \t_0, \a_4_0, \a_4_1
  sub \t_1, \a_5_0, \a_5_1
  add \a_4_0, \a_4_0, \a_4_1
  add \a_5_0, \a_5_0, \a_5_1
  mulw \a_4_1, \t_0, \t_2
  mulw \a_5_1, \t_1, \t_2
  sub \t_0, \a_6_0, \a_6_1
  sub \t_3, \a_7_0, \a_7_1
  add \a_6_0, \a_6_0, \a_6_1
  add \a_7_0, \a_7_0, \a_7_1
  mulw \a_6_1, \t_0, \t_2
  mulw \a_7_1, \t_3, \t_2
  srai \a_4_1, \a_4_1, 16
  srai \a_5_1, \a_5_1, 16
  addi \a_4_1, \a_4_1, 8
  addi \a_5_1, \a_5_1, 8
  mulh \a_4_1, \a_4_1, \q48
  mulh \a_5_1, \a_5_1, \q48
  srai \a_6_1, \a_6_1, 16
  srai \a_7_1, \a_7_1, 16
  addi \a_6_1, \a_6_1, 8
  addi \a_7_1, \a_7_1, 8
  mulh \a_6_1, \a_6_1, \q48
  mulh \a_7_1, \a_7_1, \q48
.endm

.macro plant_mul_const_inplace_x8  q48, zeta,  a_0, a_1, a_2, a_3,  a_4, a_5, a_6, a_7
  mulw \a_0, \a_0, \zeta
  mulw \a_1, \a_1, \zeta
  mulw \a_2, \a_2, \zeta
  mulw \a_3, \a_3, \zeta
  srai \a_0, \a_0, 16
  srai \a_1, \a_1, 16
  addi \a_0, \a_0, 8
  addi \a_1, \a_1, 8
  mulh \a_0, \a_0, \q48
  mulh \a_1, \a_1, \q48
  srai \a_2, \a_2, 16
  srai \a_3, \a_3, 16
  mulw \a_4, \a_4, \zeta
  mulw \a_5, \a_5, \zeta
  addi \a_2, \a_2, 8
  addi \a_3, \a_3, 8
  mulh \a_2, \a_2, \q48
  mulh \a_3, \a_3, \q48
  srai \a_4, \a_4, 16
  srai \a_5, \a_5, 16
  mulw \a_6, \a_6, \zeta
  mulw \a_7, \a_7, \zeta
  addi \a_4, \a_4, 8
  addi \a_5, \a_5, 8
  mulh \a_4, \a_4, \q48
  mulh \a_5, \a_5, \q48
  srai \a_6, \a_6, 16
  addi \a_6, \a_6, 8
  mulh \a_6, \a_6, \q48
  srai \a_7, \a_7, 16
  addi \a_7, \a_7, 8
  mulh \a_7, \a_7, \q48
.endm

// in-place plantard reduction to a
// output \in (-0.5q, 0.5q); q48: q<<48
.macro plant_red q48, qinv, a
  mulw \a, \a, \qinv
  srai \a, \a, 16
  addi \a, \a, 8
  mulh \a, \a, \q48
.endm

.macro plant_red_x4  q48, qinv,   a_0, a_1, a_2, a_3
  mulw \a_0, \a_0, \qinv
  mulw \a_1, \a_1, \qinv
  mulw \a_2, \a_2, \qinv
  mulw \a_3, \a_3, \qinv
  srai \a_0, \a_0, 16
  srai \a_1, \a_1, 16
  srai \a_2, \a_2, 16
  srai \a_3, \a_3, 16
  addi \a_0, \a_0, 8
  addi \a_1, \a_1, 8
  addi \a_2, \a_2, 8
  addi \a_3, \a_3, 8
  mulh \a_0, \a_0, \q48
  mulh \a_1, \a_1, \q48
  mulh \a_2, \a_2, \q48
  mulh \a_3, \a_3, \q48
.endm

.equ q, 3329
.equ q48, 0xd01000000000000     // q<<48
.equ qinv, 0x6ba8f301           // q^-1 mod+- 2^32
.equ plantconst, 0x13afb8       // (-2^{32} mod q)*qinv mod 2^32
.equ plantconst2, 0x97f44fac    // (2^{64} mod q)*qinv mod 2^32

// void poly_basemul_acc_cached_rv64im(int32_t *r, const int16_t *a, const int16_t *b, int16_t *b_cache)
// compute basemul using cached b_cache and accumulate the 32-bit results into r
// a0: r, a1: a, a2: b, a3: b_cache
// a5: q<<48, a6: loop control
.global poly_basemul_acc_cached_rv64im_opt_c908
.align 2
poly_basemul_acc_cached_rv64im_opt_c908:
    addi sp, sp, -8*15
    save_regs
    li a5, q48
    li a6, 32
                                // Instructions:    5
                                // Expected cycles: 5
                                // Expected IPC:    1.00
                                //
                                // Cycle bound:     5.0
                                // IPC bound:       1.00
                                //
                                // Wall time:     0.02s
                                // User time:     0.02s
                                //
                                // ----- cycle (expected) ------>
                                // 0                        25
                                // |------------------------|----
        lh x1, 2*0(x12)         // *.............................
        lh x8, 2*1(x12)         // .*............................
        lh x27, 2*0(x11)        // ..*...........................
        lh x23, 2*1(x11)        // ...*..........................
        lh x19, 2*7(x11)        // ....*.........................

                                 // ------ cycle (expected) ------>
                                 // 0                        25
                                 // |------------------------|-----
        // lh x1, 2*0(x12)       // *..............................
        // lh x8, 2*1(x12)       // .*.............................
        // lh x27, 2*0(x11)      // ..*............................
        // lh x23, 2*1(x11)      // ...*...........................
        // lh x19, 2*7(x11)      // ....*..........................

        addi a6, a6, -1
poly_basemul_acc_cached_rv64im_loop:
                                  // Instructions:    72
                                  // Expected cycles: 36
                                  // Expected IPC:    2.00
                                  //
                                  // Cycle bound:     39.0
                                  // IPC bound:       1.85
                                  //
                                  // Wall time:     65.69s
                                  // User time:     65.69s
                                  //
                                  // -------- cycle (expected) --------->
                                  // 0                        25
                                  // |------------------------|----------
        lh x17, 2*0(x13)          // *...................................
        mul x4, x23, x1           // *...................................
        mul x15, x27, x1          // .*..................................
        lh x22, 2*6(x12)          // .*..................................
        lh x3, 2*6(x11)           // ..*.................................
        mul x27, x27, x8          // ..*.................................
        mul x18, x23, x17         // ...*................................
        lh x23, 2*7(x12)          // ...*................................
        mul x30, x19, x22         // ....*...............................
        lw x7, 4*0(x10)           // ....*...............................
        mul x8, x3, x22           // .....*..............................
        lw x16, 4*1(x10)          // .....*..............................
        lh x20, 2*5(x11)          // ......*.............................
        mul x22, x3, x23          // ......*.............................
        lw x23, 4*7(x10)          // .......*............................
        add x5, x16, x27          // .......*............................
        add x7, x7, x15           // ........*...........................
        lh x15, 2*4(x11)          // ........*...........................
        add x6, x7, x18           // .........*..........................
        lh x17, 2*2(x13)          // .........*..........................
        lh x9, 2*4(x12)           // ..........*.........................
        add x22, x23, x22         // ..........*.........................
        add x26, x22, x30         // ...........*........................
        lw x7, 4*6(x10)           // ...........*........................
        mul x14, x20, x17         // ............*.......................
        lh x22, 2*5(x12)          // ............*.......................
        add x17, x7, x8           // .............*......................
        lh x31, 2*2(x12)          // .............*......................
        lh x23, 2*3(x12)          // ..............*.....................
        mul x16, x15, x9          // ..............*.....................
        addi x12, x12, 2*8        // ...............*....................
        lh x7, 2*3(x13)           // ...............*....................
        mul x18, x20, x9          // ................*...................
        lh x1, 2*0(x12)           // ................e...................
        lh x29, 2*3(x11)          // .................*..................
        mul x24, x15, x22         // .................*..................
        lw x27, 4*4(x10)          // ..................*.................
        add x25, x5, x4           // ..................*.................
        mul x20, x19, x7          // ...................*................
        lh x8, 2*1(x12)           // ...................e................
        lh x19, 2*1(x13)          // ....................*...............
        addi x13, x13, 2*4        // ....................*...............
        add x7, x27, x16          // .....................*..............
        lh x16, 2*2(x11)          // .....................*..............
        addi x11, x11, 2*8        // ......................*.............
        sw x6, 4*0(x10)           // ......................*.............
        sw x26, 4*7(x10)          // .......................*............
        add x22, x17, x20         // .......................*............
        lw x21, 4*2(x10)          // ........................*...........
        mul x26, x16, x31         // ........................*...........
        mul x9, x29, x19          // .........................*..........
        lh x27, 2*0(x11)          // .........................e..........
        mul x15, x29, x31         // ..........................*.........
        sw x22, 4*6(x10)          // ..........................*.........
        sw x25, 4*1(x10)          // ...........................*........
        mul x16, x16, x23         // ...........................*........
        lw x22, 4*5(x10)          // ............................*.......
        add x19, x21, x26         // ............................*.......
        add x4, x19, x9           // .............................*......
        lw x21, 4*3(x10)          // .............................*......
        add x7, x7, x14           // ..............................*.....
        lh x23, 2*1(x11)          // ..............................e.....
        sw x4, 4*2(x10)           // ...............................*....
        add x19, x21, x16         // ...............................*....
        add x19, x19, x15         // ................................*...
        sw x7, 4*4(x10)           // ................................*...
        sw x19, 4*3(x10)          // .................................*..
        add x22, x22, x24         // .................................*..
        add x22, x22, x18         // ..................................*.
        lh x19, 2*7(x11)          // ..................................e.
        sw x22, 4*5(x10)          // ...................................*
        addi x10, x10, 4*8        // ...................................*

                                   // ------------------ cycle (expected) ------------------->
                                   // 0                        25                       50
                                   // |------------------------|------------------------|-----
        // lh x8, 2*0(x12)         // e...................'...............~...................
        // lh x9, 2*1(x12)         // ...e................'..................~................
        // lh x19, 2*3(x12)        // ....................'.............*.....................
        // lh x21, 2*5(x12)        // ....................'...........*.......................
        // lh x23, 2*7(x12)        // ....................'..*................................
        // lh  x5, 2*0(x11)        // .........e..........'........................~..........
        // lh  x6, 2*1(x11)        // ..............e.....'.............................~.....
        // lh  x7, 2*0(x13)        // ....................*...................................
        // lh  x28, 2*1(x13)       // ....~...............'...................*...............
        // lh  x29, 2*2(x13)       // ....................'........*..........................
        // lh  x30, 2*3(x13)       // ....................'..............*....................
        // lw  x24, 4*0(x10)       // ....................'...*...............................
        // lw  x25, 4*1(x10)       // ....................'....*..............................
        // mul x18, x5, x8         // ....................'*..................................
        // mul x20, x6, x7         // ....................'..*................................
        // mul x22, x5, x9         // ....................'.*.................................
        // mul x31, x6, x8         // ....................*...................................
        // lw  x26, 4*2(x10)       // ........~...........'.......................*...........
        // lw  x27, 4*3(x10)       // .............~......'............................*......
        // add x24, x24, x18       // ....................'.......*...........................
        // add x24, x24, x20       // ....................'........*..........................
        // add x25, x25, x22       // ....................'......*............................
        // add x25, x25, x31       // ..~.................'.................*.................
        // lh  x5, 2*2(x11)        // .....~..............'....................*..............
        // lh  x6, 2*3(x11)        // .~..................'................*..................
        // lh  x18, 2*2(x12)       // ....................'............*......................
        // sw  x24, 4*0(x10)       // ......~.............'.....................*.............
        // sw  x25, 4*1(x10)       // ...........~........'..........................*........
        // mul x9, x6, x28         // .........~..........'........................*..........
        // mul x8, x5, x18         // ........~...........'.......................*...........
        // mul x24, x5, x19        // ...........~........'..........................*........
        // mul x25, x6, x18        // ..........~.........'.........................*.........
        // lh  x7, 2*4(x11)        // ....................'.......*...........................
        // lh  x4, 2*5(x11)        // ....................'.....*.............................
        // lh  x20, 2*4(x12)       // ....................'.........*.........................
        // add x26, x26, x8        // ............~.......'...........................*.......
        // add x26, x26, x9        // .............~......'............................*......
        // add x27, x27, x24       // ...............~....'..............................*....
        // add x27, x27, x25       // ................~...'...............................*...
        // sw  x26, 4*2(x10)       // ...............~....'..............................*....
        // sw  x27, 4*3(x10)       // .................~..'................................*..
        // lw  x24, 4*4(x10)       // ..~.................'.................*.................
        // lw  x25, 4*5(x10)       // ............~.......'...........................*.......
        // lw  x26, 4*6(x10)       // ....................'..........*........................
        // lw  x27, 4*7(x10)       // ....................'......*............................
        // mul x8, x7, x20         // ....................'.............*.....................
        // mul x9, x4, x29         // ....................'...........*.......................
        // mul x5, x7, x21         // .~..................'................*..................
        // mul x6, x4, x20         // ~...................'...............*...................
        // lh  x3, 2*6(x11)        // ....................'.*.................................
        // lh  x1, 2*7(x11)        // ..................e.'.................................~.
        // lh  x22, 2*6(x12)       // ....................'*..................................
        // add x24, x24, x8        // .....~..............'....................*..............
        // add x24, x24, x9        // ..............~.....'.............................*.....
        // add x25, x25, x5        // .................~..'................................*..
        // add x25, x25, x6        // ..................~.'.................................*.
        // sw  x24, 4*4(x10)       // ................~...'...............................*...
        // sw  x25, 4*5(x10)       // ...................~'..................................*
        // mul x8, x3, x22         // ....................'....*..............................
        // mul x9, x1, x30         // ...~................'..................*................
        // mul x5, x3, x23         // ....................'.....*.............................
        // mul x6, x1, x22         // ....................'...*...............................
        // add x26, x26, x8        // ....................'............*......................
        // add x26, x26, x9        // .......~............'......................*............
        // add x27, x27, x5        // ....................'.........*.........................
        // add x27, x27, x6        // ....................'..........*........................
        // sw  x26, 4*6(x10)       // ..........~.........'.........................*.........
        // sw  x27, 4*7(x10)       // .......~............'......................*............
        // addi x10, x10, 4*8      // ...................~'..................................*
        // addi x11, x11, 2*8      // ......~.............'.....................*.............
        // addi x12, x12, 2*8      // ....................'..............*....................
        // addi x13, x13, 2*4      // ....~...............'...................*...............

        addi a6, a6, -1
        bne a6, zero, poly_basemul_acc_cached_rv64im_loop
                                  // Instructions:    67
                                  // Expected cycles: 34
                                  // Expected IPC:    1.97
                                  //
                                  // Cycle bound:     34.0
                                  // IPC bound:       1.97
                                  //
                                  // Wall time:     14.08s
                                  // User time:     14.08s
                                  //
                                  // ------- cycle (expected) -------->
                                  // 0                        25
                                  // |------------------------|--------
        lh x29, 2*2(x13)          // *.................................
        mul x22, x23, x1          // *.................................
        mul x1, x27, x1           // .*................................
        lh x28, 2*0(x13)          // .*................................
        mul x20, x27, x8          // ..*...............................
        lh x4, 2*3(x13)           // ..*...............................
        lh x30, 2*1(x13)          // ...*..............................
        addi x13, x13, 2*4        // ...*..............................
        lh x27, 2*5(x12)          // ....*.............................
        mul x28, x23, x28         // ....*.............................
        mul x6, x19, x4           // .....*............................
        lw x8, 4*0(x10)           // .....*............................
        lh x18, 2*4(x11)          // ......*...........................
        add x31, x8, x1           // .......*..........................
        lh x23, 2*5(x11)          // .......*..........................
        add x26, x31, x28         // ........*.........................
        lh x4, 2*4(x12)           // ........*.........................
        mul x1, x18, x27          // .........*........................
        lw x8, 4*1(x10)           // .........*........................
        mul x17, x23, x29         // ..........*.......................
        lw x27, 4*5(x10)          // ..........*.......................
        mul x7, x18, x4           // ...........*......................
        add x21, x8, x20          // ...........*......................
        add x31, x21, x22         // ............*.....................
        lh x9, 2*3(x11)           // ............*.....................
        add x27, x27, x1          // .............*....................
        lh x20, 2*6(x12)          // .............*....................
        lw x24, 4*4(x10)          // ..............*...................
        mul x5, x23, x4           // ..............*...................
        mul x14, x9, x30          // ...............*..................
        lh x16, 2*7(x12)          // ...............*..................
        lh x1, 2*2(x11)           // ................*.................
        add x29, x24, x7          // ................*.................
        add x29, x29, x17         // .................*................
        lh x24, 2*3(x12)          // .................*................
        lh x3, 2*6(x11)           // ..................*...............
        add x8, x27, x5           // ..................*...............
        lh x21, 2*2(x12)          // ...................*..............
        addi x12, x12, 2*8        // ...................*..............
        sw x29, 4*4(x10)          // ....................*.............
        mul x25, x1, x24          // ....................*.............
        mul x23, x3, x20          // .....................*............
        lw x27, 4*3(x10)          // .....................*............
        mul x22, x9, x21          // ......................*...........
        mul x7, x1, x21           // ......................*...........
        mul x28, x3, x16          // .......................*..........
        lw x17, 4*7(x10)          // .......................*..........
        add x27, x27, x25         // ........................*.........
        lw x29, 4*2(x10)          // ........................*.........
        lw x16, 4*6(x10)          // .........................*........
        mul x15, x19, x20         // .........................*........
        add x18, x29, x7          // ..........................*.......
        add x20, x27, x22         // ..........................*.......
        sw x20, 4*3(x10)          // ...........................*......
        add x22, x18, x14         // ...........................*......
        sw x26, 4*0(x10)          // ............................*.....
        add x29, x17, x28         // ............................*.....
        sw x8, 4*5(x10)           // .............................*....
        add x29, x29, x15         // .............................*....
        sw x29, 4*7(x10)          // ..............................*...
        add x8, x16, x23          // ..............................*...
        sw x22, 4*2(x10)          // ...............................*..
        add x8, x8, x6            // ...............................*..
        sw x31, 4*1(x10)          // ................................*.
        addi x11, x11, 2*8        // ................................*.
        sw x8, 4*6(x10)           // .................................*
        addi x10, x10, 4*8        // .................................*

                                   // ------- cycle (expected) -------->
                                   // 0                        25
                                   // |------------------------|--------
        // lh x17, 2*0(x13)        // .*................................
        // mul x4, x23, x1         // *.................................
        // mul x15, x27, x1        // .*................................
        // lh x22, 2*6(x12)        // .............*....................
        // lh x3, 2*6(x11)         // ..................*...............
        // mul x27, x27, x8        // ..*...............................
        // mul x18, x23, x17       // ....*.............................
        // lh x23, 2*7(x12)        // ...............*..................
        // mul x30, x19, x22       // .........................*........
        // lw x7, 4*0(x10)         // .....*............................
        // mul x8, x3, x22         // .....................*............
        // lw x16, 4*1(x10)        // .........*........................
        // lh x20, 2*5(x11)        // .......*..........................
        // mul x22, x3, x23        // .......................*..........
        // lw x23, 4*7(x10)        // .......................*..........
        // add x5, x16, x27        // ...........*......................
        // add x7, x7, x15         // .......*..........................
        // lh x15, 2*4(x11)        // ......*...........................
        // add x6, x7, x18         // ........*.........................
        // lh x17, 2*2(x13)        // *.................................
        // lh x9, 2*4(x12)         // ........*.........................
        // add x22, x23, x22       // ............................*.....
        // add x26, x22, x30       // .............................*....
        // lw x7, 4*6(x10)         // .........................*........
        // mul x14, x20, x17       // ..........*.......................
        // lh x22, 2*5(x12)        // ....*.............................
        // add x17, x7, x8         // ..............................*...
        // lh x31, 2*2(x12)        // ...................*..............
        // lh x23, 2*3(x12)        // .................*................
        // mul x16, x15, x9        // ...........*......................
        // addi x12, x12, 2*8      // ...................*..............
        // lh x7, 2*3(x13)         // ..*...............................
        // mul x18, x20, x9        // ..............*...................
        // lh x29, 2*3(x11)        // ............*.....................
        // mul x24, x15, x22       // .........*........................
        // lw x27, 4*4(x10)        // ..............*...................
        // add x25, x5, x4         // ............*.....................
        // mul x20, x19, x7        // .....*............................
        // lh x19, 2*1(x13)        // ...*..............................
        // addi x13, x13, 2*4      // ...*..............................
        // add x7, x27, x16        // ................*.................
        // lh x16, 2*2(x11)        // ................*.................
        // addi x11, x11, 2*8      // ................................*.
        // sw x6, 4*0(x10)         // ............................*.....
        // sw x26, 4*7(x10)        // ..............................*...
        // add x22, x17, x20       // ...............................*..
        // lw x21, 4*2(x10)        // ........................*.........
        // mul x26, x16, x31       // ......................*...........
        // mul x9, x29, x19        // ...............*..................
        // mul x15, x29, x31       // ......................*...........
        // sw x22, 4*6(x10)        // .................................*
        // sw x25, 4*1(x10)        // ................................*.
        // mul x16, x16, x23       // ....................*.............
        // lw x22, 4*5(x10)        // ..........*.......................
        // add x19, x21, x26       // ..........................*.......
        // add x4, x19, x9         // ...........................*......
        // lw x21, 4*3(x10)        // .....................*............
        // add x7, x7, x14         // .................*................
        // sw x4, 4*2(x10)         // ...............................*..
        // add x19, x21, x16       // ........................*.........
        // add x19, x19, x15       // ..........................*.......
        // sw x7, 4*4(x10)         // ....................*.............
        // sw x19, 4*3(x10)        // ...........................*......
        // add x22, x22, x24       // .............*....................
        // add x22, x22, x18       // ..................*...............
        // sw x22, 4*5(x10)        // .............................*....
        // addi x10, x10, 4*8      // .................................*

    restore_regs
    addi sp, sp, 8*15
ret