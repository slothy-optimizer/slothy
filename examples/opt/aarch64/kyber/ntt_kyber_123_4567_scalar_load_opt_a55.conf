# This configuration was used to generate the most recent optimized code for 
# the ntt_kyber_123_4567_scalar_load_opt_a55 example.

class ntt_kyber_123_4567(OptimizationRunner):
    def __init__(
        self, var="", arch=AArch64_Neon, target=Target_CortexA55, timeout=None
    ):
        name = "ntt_kyber_123_4567"
        infile = name

        self.var = var

        super().__init__(
            infile,
            name,
            rename=True,
            arch=arch,
            target=target,
            timeout=timeout,
            subfolder=SUBFOLDER,
            var=var,
        )

    def core(self, slothy):
        slothy.config.sw_pipelining.enabled = True
        slothy.config.inputs_are_outputs = True
        slothy.config.sw_pipelining.minimize_overlapping = False
        slothy.config.variable_size = True
        slothy.config.reserved_regs = [f"x{i}" for i in range(0, 7)] + ["x30", "sp"]
        slothy.config.reserved_regs += self.target_reserved
        slothy.config.constraints.stalls_first_attempt = 64
        slothy.optimize_loop("layer123_start")
        slothy.optimize_loop("layer4567_start")
        # Build + emulate entire function to test that behaviour has not changed
        if self.var == "":
            slothy.global_selftest(
                "ntt_kyber_123_4567",
                {"x0": 1024, "x1": 1024, "x3": 1024, "x4": 1024, "x5": 1024},
            )

