.syntax unified
.cpu cortex-m4
.thumb

// q locate in the top half of the register
.macro plant_red q, qa, qinv, tmp
 mul \tmp, \tmp, \qinv
 // tmp*qinv mod 2^2n/ 2^n; in high half
 smlatt \tmp, \tmp, \q, \qa
 // result in high half
.endm

.macro doublebasemul_frombytes_asm_acc rptr, bptr, zeta, poly0, poly1, poly3, res0, tmp, tmp2, q, qa, qinv

 ldr \poly0, [\bptr], #8

 ldr \res0, [\rptr]
 smulwt \tmp, \zeta, \poly1
 // b_1*zeta*qinv*plant_const; in low half
 smlabt \tmp, \tmp, \q, \qa
 // b_1*zeta
 smultt \tmp, \poly0, \tmp
 // a_1*b_1*zeta <2^32
 smlabb \tmp, \poly0, \poly1, \tmp
 // a1*b1*zeta+a0*b0
 plant_red \q, \qa, \qinv, \tmp
 // r[0] in upper half of tmp

 smuadx \tmp2, \poly0, \poly1
 plant_red \q, \qa, \qinv, \tmp2

 // r[1] in upper half of tmp2
 pkhtb \tmp, \tmp2, \tmp, asr #16
 uadd16 \res0, \res0, \tmp
 str \res0, [\rptr], #8 // @slothy:core // @slothy:before=cmp

 neg \zeta, \zeta

 ldr \poly0, [\bptr, #-4]
 ldr \res0, [\rptr, #-4]

 smulwt \tmp, \zeta, \poly3
 smlabt \tmp, \tmp, \q, \qa
 smultt \tmp, \poly0, \tmp
 smlabb \tmp, \poly0, \poly3, \tmp
 plant_red \q, \qa, \qinv, \tmp
 // r[0] in upper half of tmp

 smuadx \tmp2, \poly0, \poly3
 plant_red \q, \qa, \qinv, \tmp2
 // r[1] in upper half of tmp2
 pkhtb \tmp, \tmp2, \tmp, asr #16
 uadd16 \res0, \res0, \tmp
 str \res0, [\rptr, #-4]
.endm

// reduce 2 registers
.macro deserialize aptr, tmp, tmp2, tmp3, t0, t1
 ldrb.w \tmp, [\aptr, #2]
 ldrh.w \tmp2, [\aptr, #3]
 ldrb.w \tmp3, [\aptr, #5]
 ldrh.w \t0, [\aptr], #6

 ubfx \t1, \t0, #12, #4
 ubfx \t0, \t0, #0, #12
 orr \t1, \t1, \tmp, lsl #4
 orr \t0, \t0, \t1, lsl #16
 // tmp is free now
 ubfx \t1, \tmp2, #12, #4
 ubfx \tmp, \tmp2, #0, #12
 orr \t1, \t1, \tmp3, lsl #4
 orr \t1, \tmp, \t1, lsl #16
.endm

// void frombytes_mul_asm_acc(int16_t *r, const int16_t *b, const unsigned char *a, const int32_t zetas[64])
.global frombytes_mul_asm_acc_opt_m7
.type frombytes_mul_asm_acc_opt_m7, %function
.align 2
frombytes_mul_asm_acc_opt_m7:
 push {r4-r11, r14}

 rptr    .req r0
 bptr    .req r1
 aptr    .req r2
 zetaptr .req r3
 t0      .req r4
 t1      .req r5
 tmp     .req r6
 tmp2    .req r7
 tmp3    .req r8
 q       .req r9
 qa      .req r10
 qinv    .req r11
 zeta    .req r12
 ctr     .req r14

 movw qa, #26632
 movt  q, #3329
 ### qinv=0x6ba8f301
 movw qinv, #62209
 movt qinv, #27560

 add ctr, rptr, #64*4*2
                                    // Instructions:    5
                                    // Expected cycles: 5
                                    // Expected IPC:    1.00
                                    //
                                    // Cycle bound:     5.0
                                    // IPC bound:       1.00
                                    //
                                    // Wall time:     0.01s
                                    // User time:     0.01s
                                    //
                                    // ----- cycle (expected) ------>
                                    // 0                        25
                                    // |------------------------|----
        ldrb.w r8, [r2, #2]         // *.............................
        ldrh.w r5, [r2, #3]         // *.............................
        ldrb.w r7, [r2, #5]         // .*............................
        ldrh.w r4, [r2], #6         // .*............................
        ubfx r6, r4, #12, #4        // ....*.........................

                                     // ------ cycle (expected) ------>
                                     // 0                        25
                                     // |------------------------|-----
        // ldrb.w r8, [r2, #2]       // *..............................
        // ldrh.w r5, [r2, #3]       // *..............................
        // ldrb.w r7, [r2, #5]       // .*.............................
        // ldrh.w r4, [r2], #6       // .*.............................
        // ubfx r6, r4, #12, #4      // ....*..........................

        push {r14}
        vmov r14, s0
        sub r14, r14, #8
        vmov s0, r14
        pop {r14}
1:
                                          // Instructions:    46
                                          // Expected cycles: 26
                                          // Expected IPC:    1.77
                                          //
                                          // Cycle bound:     28.0
                                          // IPC bound:       1.64
                                          //
                                          // Wall time:     8.16s
                                          // User time:     8.16s
                                          //
                                          // ----- cycle (expected) ------>
                                          // 0                        25
                                          // |------------------------|----
        orr r12, r6, r8, lsl #4           // *.............................
        ldr.w r6, [r3], #4                // *.............................
        ubfx r8, r4, #0, #12              // .*............................
        ldr r4, [r1], #8                  // .*............................
        orr r8, r8, r12, lsl #16          // ..*...........................
        vmov s0, r14                      // ..*...........................
        ubfx r12, r5, #12, #4             // ...*..........................
        smuadx r14, r4, r8                // ...*..........................
        orr r12, r12, r7, lsl #4          // ....*.........................
        smulwt r7, r6, r8                 // ....*.........................
        ubfx r5, r5, #0, #12              // .....*........................
        mul r14, r14, r11                 // .....*........................
        orr r12, r5, r12, lsl #16         // ......*.......................
        smlabt r5, r7, r9, r10            // ......*.......................
        neg r6, r6                        // .......*......................
        smlatt r7, r14, r9, r10           // .......*......................
        smultt r5, r4, r5                 // ........*.....................
        smlabb r4, r4, r8, r5             // .........*....................
        ldr r8, [r1, #-4]                 // ..........*...................
        smulwt r5, r6, r12                // ..........*...................
        mul r6, r4, r11                   // ...........*..................
        ldr r4, [r0]                      // ............*.................
        smlabt r5, r5, r9, r10            // ............*.................
        smlatt r6, r6, r9, r10            // .............*................
        smultt r5, r8, r5                 // ..............*...............
        vmov r14, s0                      // ...............*..............
        smlabb r5, r8, r12, r5            // ...............*..............
        pkhtb r6, r7, r6, asr #16         // ................*.............
        smuadx r7, r8, r12                // ................*.............
        uadd16 r4, r4, r6                 // .................*............
        mul r6, r5, r11                   // .................*............
        ldrb.w r8, [r2, #2]               // ..................e...........
        mul r12, r7, r11                  // ..................*...........
        ldrh.w r5, [r2, #3]               // ...................e..........
        smlatt r6, r6, r9, r10            // ...................*..........
        ldrb.w r7, [r2, #5]               // ....................e.........
        smlatt r12, r12, r9, r10          // ....................*.........
        str r4, [r0], #8                  // .....................*........ // @slothy:core // @slothy:before=cmp
        ldrh.w r4, [r2], #6               // .....................e........
        pkhtb r6, r12, r6, asr #16        // ......................*.......
        ldr r12, [r0, #-4]                // ......................*.......
        uadd16 r12, r12, r6               // .......................*......
        cmp.w r0, r14                     // .......................*...... // @slothy:id=cmp
        ubfx r6, r4, #12, #4              // ........................e.....
        str r12, [r0, #-4]                // ........................*.....
        bne.w 1b                          // .........................*.... // @slothy:branch

                                          // ------- cycle (expected) -------->
                                          // 0                        25
                                          // |------------------------|--------
        // ldr.w r12, [r3], #4            // ........*.........................
        // ldrb.w r6, [r2, #2]            // e.......'.................~.......
        // ldrh.w r7, [r2, #3]            // .e......'..................~......
        // ldrb.w r8, [r2, #5]            // ..e.....'...................~.....
        // ldrh.w r4, [r2], #6            // ...e....'....................~....
        // ubfx r5, r4, #12, #4           // ......e.'.......................~.
        // ubfx r4, r4, #0, #12           // ........'*........................
        // orr r5, r5, r6, lsl #4         // ........*.........................
        // orr r4, r4, r5, lsl #16        // ........'.*.......................
        // ubfx r5, r7, #12, #4           // ........'..*......................
        // ubfx r6, r7, #0, #12           // ........'....*....................
        // orr r5, r5, r8, lsl #4         // ........'...*.....................
        // orr r5, r6, r5, lsl #16        // ........'.....*...................
        // vmov s0, r14                   // ........'.*.......................
        // ldr r8, [r1], #8               // ........'*........................
        // ldr r14, [r0]                  // ........'...........*.............
        // smulwt r6, r12, r4             // ........'...*.....................
        // smlabt r6, r6, r9, r10         // ........'.....*...................
        // smultt r6, r8, r6              // ........'.......*.................
        // smlabb r6, r8, r4, r6          // ........'........*................
        // mul r6, r6, r11                // ........'..........*..............
        // smlatt r6, r6, r9, r10         // ........'............*............
        // smuadx r7, r8, r4              // ........'..*......................
        // mul r7, r7, r11                // ........'....*....................
        // smlatt r7, r7, r9, r10         // ........'......*..................
        // pkhtb r6, r7, r6, asr #16      // ........'...............*.........
        // uadd16 r14, r14, r6            // ........'................*........
        // str r14, [r0], #8              // ...~....'....................*....
        // neg r12, r12                   // ........'......*..................
        // ldr r8, [r1, #-4]              // ........'.........*...............
        // ldr r14, [r0, #-4]             // ....~...'.....................*...
        // smulwt r6, r12, r5             // ........'.........*...............
        // smlabt r6, r6, r9, r10         // ........'...........*.............
        // smultt r6, r8, r6              // ........'.............*...........
        // smlabb r6, r8, r5, r6          // ........'..............*..........
        // mul r6, r6, r11                // ........'................*........
        // smlatt r6, r6, r9, r10         // .~......'..................*......
        // smuadx r7, r8, r5              // ........'...............*.........
        // mul r7, r7, r11                // ~.......'.................*.......
        // smlatt r7, r7, r9, r10         // ..~.....'...................*.....
        // pkhtb r6, r7, r6, asr #16      // ....~...'.....................*...
        // uadd16 r14, r14, r6            // .....~..'......................*..
        // str r14, [r0, #-4]             // ......~.'.......................*.
        // vmov r14, s0                   // ........'..............*..........
        // cmp.w r0, r14                  // .....~..'......................*..
        // bne.w 1b                       // .......~'........................*


                                          // Instructions:    41
                                          // Expected cycles: 26
                                          // Expected IPC:    1.58
                                          //
                                          // Cycle bound:     26.0
                                          // IPC bound:       1.58
                                          //
                                          // Wall time:     1.19s
                                          // User time:     1.19s
                                          //
                                          // ----- cycle (expected) ------>
                                          // 0                        25
                                          // |------------------------|----
        ldr r12, [r1], #8                 // *.............................
        orr r8, r6, r8, lsl #4            // *.............................
        ubfx r4, r4, #0, #12              // .*............................
        ldr.w r6, [r3], #4                // .*............................
        vmov s0, r14                      // ..*...........................
        orr r8, r4, r8, lsl #16           // ..*...........................
        ubfx r14, r5, #12, #4             // ...*..........................
        smulwt r4, r6, r8                 // ...*..........................
        orr r7, r14, r7, lsl #4           // ....*.........................
        smuadx r14, r12, r8               // ....*.........................
        ubfx r5, r5, #0, #12              // .....*........................
        smlabt r4, r4, r9, r10            // .....*........................
        orr r5, r5, r7, lsl #16           // ......*.......................
        mul r14, r14, r11                 // ......*.......................
        neg r6, r6                        // .......*......................
        smultt r4, r12, r4                // .......*......................
        smlabb r8, r12, r8, r4            // ........*.....................
        ldr r12, [r1, #-4]                // .........*....................
        smulwt r7, r6, r5                 // .........*....................
        mul r8, r8, r11                   // ..........*...................
        smlabt r7, r7, r9, r10            // ...........*..................
        smlatt r8, r8, r9, r10            // ............*.................
        ldr r6, [r0]                      // .............*................
        smlatt r4, r14, r9, r10           // .............*................
        vmov r14, s0                      // ..............*...............
        smultt r7, r12, r7                // ..............*...............
        pkhtb r4, r4, r8, asr #16         // ...............*..............
        smlabb r8, r12, r5, r7            // ...............*..............
        uadd16 r4, r6, r4                 // ................*.............
        str r4, [r0], #8                  // ................*............. // @slothy:core // @slothy:before=cmp
        cmp.w r0, r14                     // .................*............ // @slothy:id=cmp
        smuadx r4, r12, r5                // .................*............
        ldr r7, [r0, #-4]                 // ..................*...........
        mul r12, r8, r11                  // ..................*...........
        mul r5, r4, r11                   // ...................*..........
        smlatt r12, r12, r9, r10          // ....................*.........
        smlatt r5, r5, r9, r10            // .....................*........
        pkhtb r8, r5, r12, asr #16        // .......................*......
        uadd16 r8, r7, r8                 // ........................*.....
        str r8, [r0, #-4]                 // ........................*.....

                                           // ------ cycle (expected) ------>
                                           // 0                        25
                                           // |------------------------|-----
        // orr r12, r6, r8, lsl #4         // *..............................
        // ldr.w r6, [r3], #4              // .*.............................
        // ubfx r8, r4, #0, #12            // .*.............................
        // ldr r4, [r1], #8                // *..............................
        // orr r8, r8, r12, lsl #16        // ..*............................
        // vmov s0, r14                    // ..*............................
        // ubfx r12, r5, #12, #4           // ...*...........................
        // smuadx r14, r4, r8              // ....*..........................
        // orr r12, r12, r7, lsl #4        // ....*..........................
        // smulwt r7, r6, r8               // ...*...........................
        // ubfx r5, r5, #0, #12            // .....*.........................
        // mul r14, r14, r11               // ......*........................
        // orr r12, r5, r12, lsl #16       // ......*........................
        // smlabt r5, r7, r9, r10          // .....*.........................
        // neg r6, r6                      // .......*.......................
        // smlatt r7, r14, r9, r10         // .............*.................
        // smultt r5, r4, r5               // .......*.......................
        // smlabb r4, r4, r8, r5           // ........*......................
        // ldr r8, [r1, #-4]               // .........*.....................
        // smulwt r5, r6, r12              // .........*.....................
        // mul r6, r4, r11                 // ..........*....................
        // ldr r4, [r0]                    // .............*.................
        // smlabt r5, r5, r9, r10          // ...........*...................
        // smlatt r6, r6, r9, r10          // ............*..................
        // smultt r5, r8, r5               // ..............*................
        // vmov r14, s0                    // ..............*................
        // smlabb r5, r8, r12, r5          // ...............*...............
        // pkhtb r6, r7, r6, asr #16       // ...............*...............
        // smuadx r7, r8, r12              // .................*.............
        // uadd16 r4, r4, r6               // ................*..............
        // mul r6, r5, r11                 // ..................*............
        // mul r12, r7, r11                // ...................*...........
        // smlatt r6, r6, r9, r10          // ....................*..........
        // smlatt r12, r12, r9, r10        // .....................*.........
        // str r4, [r0], #8                // ................*..............
        // pkhtb r6, r12, r6, asr #16      // .......................*.......
        // ldr r12, [r0, #-4]              // ..................*............
        // uadd16 r12, r12, r6             // ........................*......
        // cmp.w r0, r14                   // .................*.............
        // str r12, [r0, #-4]              // ........................*......
        // bne.w 1b                        // .........................*.....


 pop {r4-r11, pc}

.size frombytes_mul_asm_acc_opt_m7, .-frombytes_mul_asm_acc_opt_m7