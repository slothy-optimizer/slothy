        .syntax unified
        .type   floatingpoint_radix4_fft_opt_M55, %function
        .global floatingpoint_radix4_fft_opt_M55


        inA .req r0
        pW0 .req r1 // Use the same twiddle data for TESTING ONLY
        sz  .req r2

        inB .req r3
        inC .req r4
        inD .req r5

        pW1 .req r6
        pW2 .req r7
        pW3 .req r8

        // NOTE:
        // We deliberately leave some aliases undefined
        // SLOTHY will fill them in as part of a 'dry-run'
        // merely concretizing symbolic registers, but not
        // yet reordering.

        .text
        .align 4
floatingpoint_radix4_fft_opt_M55:
        push    {r4-r12,lr}
        vpush   {d0-d15}

        add     inB, inA, sz
        add     inC, inB, sz
        add     inD, inC, sz

        add     pW1, pW0, sz
        add     pW2, pW1, sz
        add     pW3, pW2, sz

        lsr     lr, sz, #4
        wls     lr, lr, end

.macro load_data
        vldrw.32   qA, [inA]
        vldrw.32   qB, [inB]
        vldrw.32   qC, [inC]
        vldrw.32   qD, [inD]
.endm

.macro load_twiddles
        vldrw.s32  qTw1, [pW1], #16
        vldrw.s32  qTw2, [pW2], #16
        vldrw.s32  qTw3, [pW3], #16
.endm

.macro store_data
        vstrw.32   qA, [inA], #16
        vstrw.32   qB, [inB], #16
        vstrw.32   qC, [inC], #16
        vstrw.32   qD, [inD], #16
.endm

.macro cmul_flt out, in0, in1
        vcmul.f32  \out, \in0, \in1, #0
        vcmla.f32  \out, \in0, \in1, #270
.endm

        vldrw.32 q2, [r5]          // *..
        // gap                     // ...
        vldrw.32 q6, [r3]          // .*.
        // gap                     // ...
        vldrw.32 q1, [r4]          // ..*
        
        // original source code
        // vldrw.32 q2, [r5]      // *.. 
        // vldrw.32 q6, [r3]      // .*. 
        // vldrw.32 q1, [r4]      // ..* 
        
        sub lr, lr, #1
.p2align 2
flt_radix4_fft_loop_start:
        vadd.f32 q0, q6, q2                // ........*................
        // gap                             // .........................
        vsub.f32 q6, q6, q2                // ..........*..............
        vldrw.32 q4, [r0]                  // *........................
        vadd.f32 q5, q4, q1                // .......*.................
        vldrw.s32 q3, [r6] , #16           // ....*....................
        vadd.f32 q2, q5, q0                // ...........*.............
        vstrw.u32 q2, [r0] , #16           // .....................*...
        vsub.f32 q7, q5, q0                // ............*............
        // gap                             // .........................
        vcmul.f32 q0, q3, q7, #0           // ...............*.........
        vldrw.32 q2, [r5, #16]             // ...e.....................
        vcmla.f32 q0, q3, q7, #270         // ................*........
        vstrw.u32 q0, [r3] , #16           // ......................*..
        vsub.f32 q1, q4, q1                // .........*...............
        // gap                             // .........................
        vcadd.f32 q5, q1, q6, #90          // ..............*..........
        vldrw.s32 q0, [r8] , #16           // ......*..................
        vcadd.f32 q7, q1, q6, #270         // .............*...........
        vldrw.s32 q4, [r7] , #16           // .....*...................
        vcmul.f32 q3, q4, q7, #0           // .................*.......
        vldrw.32 q6, [r3]                  // .e.......................
        vcmla.f32 q3, q4, q7, #270         // ..................*......
        vldrw.32 q1, [r4, #16]             // ..e......................
        vcmul.f32 q7, q0, q5, #0           // ...................*.....
        vstrw.u32 q3, [r4] , #16           // .......................*.
        vcmla.f32 q7, q0, q5, #270         // ....................*....
        vstrw.u32 q7, [r5] , #16           // ........................*
        
        // original source code
        // vldrw.32   qA, [r0]                   // ................|.*...................... 
        // vldrw.32   qB, [r3]                   // .........e......|.................e...... 
        // vldrw.32   qC, [r4]                   // ...........e....|...................e.... 
        // vldrw.32   qD, [r5]                   // e...............|........e............... 
        // vldrw.s32  qTw1, [r6], #16            // ................|...*.................... 
        // vldrw.s32  qTw2, [r7], #16            // .......*........|...............*........ 
        // vldrw.s32  qTw3, [r8], #16            // .....*..........|.............*.......... 
        // vadd.f32  qSm0,  qA,   qC             // ................|..*..................... 
        // vadd.f32  qSm1,  qB,   qD             // ................*........................ 
        // vsub.f32  qDf0, qA,   qC              // ...*............|...........*............ 
        // vsub.f32  qDf1, qB,   qD              // ................|*....................... 
        // vadd.f32  qA,   qSm0,  qSm1           // ................|....*................... 
        // vsub.f32  qBp,  qSm0,  qSm1           // ................|......*................. 
        // vcadd.f32 qCp,  qDf0, qDf1, #270      // ......*.........|..............*......... 
        // vcadd.f32 qDp,  qDf0, qDf1, #90       // ....*...........|............*........... 
        // vcmul.f32  qB, qTw1, qBp, #0          // ................|.......*................ 
        // vcmla.f32  qB, qTw1, qBp, #270        // .*..............|.........*.............. 
        // vcmul.f32  qC, qTw2, qCp, #0          // ........*.......|................*....... 
        // vcmla.f32  qC, qTw2, qCp, #270        // ..........*.....|..................*..... 
        // vcmul.f32  qD, qTw3, qDp, #0          // ............*...|....................*... 
        // vcmla.f32  qD, qTw3, qDp, #270        // ..............*.|......................*. 
        // vstrw.32   qA, [r0], #16              // ................|.....*.................. 
        // vstrw.32   qB, [r3], #16              // ..*.............|..........*............. 
        // vstrw.32   qC, [r4], #16              // .............*..|.....................*.. 
        // vstrw.32   qD, [r5], #16              // ...............*|.......................* 
        
        le lr, flt_radix4_fft_loop_start
        vadd.f32 q5, q6, q2                // *.....................
        vldrw.32 q3, [r0]                  // ..*...................
        vsub.f32 q0, q6, q2                // .*....................
        vldrw.s32 q4, [r6] , #16           // ....*.................
        vadd.f32 q7, q3, q1                // ...*..................
        vldrw.s32 q2, [r8] , #16           // .............*........
        vsub.f32 q3, q3, q1                // ...........*..........
        vldrw.s32 q1, [r7] , #16           // ...............*......
        vadd.f32 q6, q7, q5                // .....*................
        vstrw.u32 q6, [r0] , #16           // ......*...............
        vsub.f32 q5, q7, q5                // .......*..............
        // gap                             // ......................
        vcadd.f32 q7, q3, q0, #90          // ............*.........
        // gap                             // ......................
        vcadd.f32 q6, q3, q0, #270         // ..............*.......
        // gap                             // ......................
        vcmul.f32 q3, q4, q5, #0           // ........*.............
        // gap                             // ......................
        vcmla.f32 q3, q4, q5, #270         // .........*............
        vstrw.u32 q3, [r3] , #16           // ..........*...........
        vcmul.f32 q5, q2, q7, #0           // ..................*...
        // gap                             // ......................
        vcmla.f32 q5, q2, q7, #270         // ....................*.
        vstrw.u32 q5, [r5] , #16           // .....................*
        vcmul.f32 q5, q1, q6, #0           // ................*.....
        // gap                             // ......................
        vcmla.f32 q5, q1, q6, #270         // .................*....
        vstrw.u32 q5, [r4] , #16           // ...................*..
        
        // original source code
        // vadd.f32 q0, q6, q2             // *..................... 
        // vsub.f32 q6, q6, q2             // ..*................... 
        // vldrw.32 q4, [r0]               // .*.................... 
        // vadd.f32 q5, q4, q1             // ....*................. 
        // vldrw.s32 q3, [r6] , #16        // ...*.................. 
        // vadd.f32 q2, q5, q0             // ........*............. 
        // vstrw.u32 q2, [r0] , #16        // .........*............ 
        // vsub.f32 q7, q5, q0             // ..........*........... 
        // vcmul.f32 q0, q3, q7, #0        // .............*........ 
        // vcmla.f32 q0, q3, q7, #270      // ..............*....... 
        // vstrw.u32 q0, [r3] , #16        // ...............*...... 
        // vsub.f32 q1, q4, q1             // ......*............... 
        // vcadd.f32 q5, q1, q6, #90       // ...........*.......... 
        // vldrw.s32 q0, [r8] , #16        // .....*................ 
        // vcadd.f32 q7, q1, q6, #270      // ............*......... 
        // vldrw.s32 q4, [r7] , #16        // .......*.............. 
        // vcmul.f32 q3, q4, q7, #0        // ...................*.. 
        // vcmla.f32 q3, q4, q7, #270      // ....................*. 
        // vcmul.f32 q7, q0, q5, #0        // ................*..... 
        // vstrw.u32 q3, [r4] , #16        // .....................* 
        // vcmla.f32 q7, q0, q5, #270      // .................*.... 
        // vstrw.u32 q7, [r5] , #16        // ..................*... 
        

end:
        vpop    {d0-d15}
        pop     {r4-r12,lr}
        bx      lr